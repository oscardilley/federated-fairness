{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6xTb4CL7RQg"
      },
      "source": [
        "## Federated Fairness Analytics - FedAvg\n",
        "Evaluating fairness for FedAvg on the FEMNIST dataset in the iid setting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFhGoUdAMWVf"
      },
      "source": [
        "### Imports, Dependencies and Config\n",
        "Firstly, installing the dependencies and importing what we need."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "syZFYfdi7pSx",
        "outputId": "4c5642bc-1d2f-4975-d415-d00522f7cd36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.17.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m65.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m76.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/dist-packages (4.9.4)\n",
            "Collecting tensorflow-federated\n",
            "  Downloading tensorflow_federated-0.74.0-py3-none-manylinux_2_31_x86_64.whl (70.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.7/70.7 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.7)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.10.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.62.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (8.1.7)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (0.1.8)\n",
            "Requirement already satisfied: etils[enp,epath,etree]>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (1.7.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (2.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (5.9.5)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (2.31.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (1.14.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (0.10.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (4.66.2)\n",
            "Requirement already satisfied: array-record>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (0.5.0)\n",
            "Requirement already satisfied: attrs~=23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-federated) (23.2.0)\n",
            "Requirement already satisfied: cachetools~=5.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow-federated) (5.3.3)\n",
            "Collecting dp-accounting==0.4.3 (from tensorflow-federated)\n",
            "  Downloading dp_accounting-0.4.3-py3-none-any.whl (104 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.8/104.8 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting farmhashpy==0.4.0 (from tensorflow-federated)\n",
            "  Downloading farmhashpy-0.4.0.tar.gz (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting google-vizier==0.1.11 (from tensorflow-federated)\n",
            "  Downloading google_vizier-0.1.11-py3-none-any.whl (721 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m721.6/721.6 kB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jaxlib==0.4.14 (from tensorflow-federated)\n",
            "  Downloading jaxlib-0.4.14-cp310-cp310-manylinux2014_x86_64.whl (73.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.7/73.7 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jax==0.4.14 (from tensorflow-federated)\n",
            "  Downloading jax-0.4.14.tar.gz (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m77.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting portpicker~=1.6 (from tensorflow-federated)\n",
            "  Downloading portpicker-1.6.0-py3-none-any.whl (16 kB)\n",
            "Collecting scipy~=1.9.3 (from tensorflow-federated)\n",
            "  Downloading scipy-1.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.7/33.7 MB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting semantic-version~=2.6 (from tensorflow-federated)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting tensorflow-compression==2.14.*,>=2.14.0 (from tensorflow-federated)\n",
            "  Downloading tensorflow_compression-2.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (262 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m262.5/262.5 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-model-optimization==0.7.5 (from tensorflow-federated)\n",
            "  Downloading tensorflow_model_optimization-0.7.5-py2.py3-none-any.whl (241 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.2/241.2 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-privacy==0.9.0 (from tensorflow-federated)\n",
            "  Downloading tensorflow_privacy-0.9.0-py3-none-any.whl (323 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.2/323.2 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow\n",
            "  Downloading tensorflow-2.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (489.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m489.9/489.9 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions>=3.6.6 (from tensorflow)\n",
            "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
            "Collecting googleapis-common-protos==1.61.0 (from tensorflow-federated)\n",
            "  Downloading googleapis_common_protos-1.61.0-py2.py3-none-any.whl (230 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m230.9/230.9 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboard<2.15,>=2.14 (from tensorflow)\n",
            "  Downloading tensorboard-2.14.1-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator<2.15,>=2.14.0 (from tensorflow)\n",
            "  Downloading tensorflow_estimator-2.14.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras<2.15,>=2.14.0 (from tensorflow)\n",
            "  Downloading keras-2.14.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath~=1.2 in /usr/local/lib/python3.10/dist-packages (from dp-accounting==0.4.3->tensorflow-federated) (1.3.0)\n",
            "Collecting attrs~=23.1 (from tensorflow-federated)\n",
            "  Downloading attrs-23.1.0-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting grpcio-tools>=1.35.0 (from google-vizier==0.1.11->tensorflow-federated)\n",
            "  Downloading grpcio_tools-1.62.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m104.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sqlalchemy<=1.4.20,>=1.4 (from google-vizier==0.1.11->tensorflow-federated)\n",
            "  Downloading SQLAlchemy-1.4.20.tar.gz (7.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m98.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "INFO: pip is looking at multiple versions of tensorflow-compression to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tensorflow-compression==2.14.*,>=2.14.0 (from tensorflow-federated)\n",
            "  Downloading tensorflow_compression-2.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (257 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m257.7/257.7 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-probability~=0.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow-compression==2.14.*,>=2.14.0->tensorflow-federated) (0.23.0)\n",
            "Collecting packaging (from tensorflow)\n",
            "  Downloading packaging-22.0-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn==1.*,>=1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-privacy==0.9.0->tensorflow-federated) (1.2.2)\n",
            "Collecting tensorflow-probability~=0.15 (from tensorflow-compression==2.14.*,>=2.14.0->tensorflow-federated)\n",
            "  Downloading tensorflow_probability-0.22.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m97.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.*,>=1.0->tensorflow-privacy==0.9.0->tensorflow-federated) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.*,>=1.0->tensorflow-privacy==0.9.0->tensorflow-federated) (3.3.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets) (2023.6.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets) (6.3.2)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets) (3.18.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets) (2024.2.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.27.0)\n",
            "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.15,>=2.14->tensorflow)\n",
            "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (1.4.0)\n",
            "INFO: pip is looking at multiple versions of grpcio-tools to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting grpcio-tools>=1.35.0 (from google-vizier==0.1.11->tensorflow-federated)\n",
            "  Downloading grpcio_tools-1.62.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m109.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading grpcio_tools-1.60.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m92.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading grpcio_tools-1.60.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m104.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading grpcio_tools-1.59.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m95.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading grpcio_tools-1.59.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m105.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading grpcio_tools-1.59.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m88.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading grpcio_tools-1.58.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m93.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of grpcio-tools to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading grpcio_tools-1.57.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m96.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading grpcio_tools-1.56.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m86.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading grpcio_tools-1.56.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m98.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading grpcio_tools-1.55.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m104.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading grpcio_tools-1.54.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m100.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading grpcio_tools-1.54.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m91.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading grpcio_tools-1.54.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m94.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading grpcio_tools-1.53.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m99.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading grpcio_tools-1.53.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m103.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading grpcio_tools-1.53.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m109.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading grpcio_tools-1.51.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m106.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading grpcio_tools-1.51.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m100.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading grpcio_tools-1.50.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m96.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading grpcio_tools-1.49.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m100.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading grpcio_tools-1.48.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m78.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<=1.4.20,>=1.4->google-vizier==0.1.11->tensorflow-federated) (3.0.3)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability~=0.15->tensorflow-compression==2.14.*,>=2.14.0->tensorflow-federated) (4.4.2)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability~=0.15->tensorflow-compression==2.14.*,>=2.14.0->tensorflow-federated) (2.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (3.2.2)\n",
            "Building wheels for collected packages: farmhashpy, jax, sqlalchemy\n",
            "  Building wheel for farmhashpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for farmhashpy: filename=farmhashpy-0.4.0-cp310-cp310-linux_x86_64.whl size=87303 sha256=1583d837ee6bbae4fc280fbdb9709d9970652f770c1863170b87fdafc756c421\n",
            "  Stored in directory: /root/.cache/pip/wheels/14/0e/36/b61b3f47ae366b7d5dd2b746326d17234269dbc745ad554857\n",
            "  Building wheel for jax (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jax: filename=jax-0.4.14-py3-none-any.whl size=1535361 sha256=06f16204915024d4d25a743efcb80b34d410097a21c4da5a1510fdfcb3ef6126\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/52/e7/dfa571c9f9b879e3facaa1584f52be04c4c3d1e14054ef40ab\n",
            "  Building wheel for sqlalchemy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlalchemy: filename=SQLAlchemy-1.4.20-cp310-cp310-linux_x86_64.whl size=1529864 sha256=43070404888f90c49338f27c0218e354778efc4613adac93d7937fce8473f185\n",
            "  Stored in directory: /root/.cache/pip/wheels/c4/42/20/a958989c470cc1a6fe1d1279b0193f0e508161327fc3d951d9\n",
            "Successfully built farmhashpy jax sqlalchemy\n",
            "Installing collected packages: typing-extensions, tensorflow-probability, tensorflow-model-optimization, tensorflow-estimator, sqlalchemy, semantic-version, scipy, portpicker, packaging, keras, grpcio-tools, googleapis-common-protos, farmhashpy, attrs, jaxlib, jax, google-vizier, dp-accounting, google-auth-oauthlib, tensorboard, tensorflow, tensorflow-privacy, tensorflow-compression, tensorflow-federated\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.10.0\n",
            "    Uninstalling typing_extensions-4.10.0:\n",
            "      Successfully uninstalled typing_extensions-4.10.0\n",
            "  Attempting uninstall: tensorflow-probability\n",
            "    Found existing installation: tensorflow-probability 0.23.0\n",
            "    Uninstalling tensorflow-probability-0.23.0:\n",
            "      Successfully uninstalled tensorflow-probability-0.23.0\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.15.0\n",
            "    Uninstalling tensorflow-estimator-2.15.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.15.0\n",
            "  Attempting uninstall: sqlalchemy\n",
            "    Found existing installation: SQLAlchemy 2.0.28\n",
            "    Uninstalling SQLAlchemy-2.0.28:\n",
            "      Successfully uninstalled SQLAlchemy-2.0.28\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.11.4\n",
            "    Uninstalling scipy-1.11.4:\n",
            "      Successfully uninstalled scipy-1.11.4\n",
            "  Attempting uninstall: portpicker\n",
            "    Found existing installation: portpicker 1.5.2\n",
            "    Uninstalling portpicker-1.5.2:\n",
            "      Successfully uninstalled portpicker-1.5.2\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.15.0\n",
            "    Uninstalling keras-2.15.0:\n",
            "      Successfully uninstalled keras-2.15.0\n",
            "  Attempting uninstall: googleapis-common-protos\n",
            "    Found existing installation: googleapis-common-protos 1.63.0\n",
            "    Uninstalling googleapis-common-protos-1.63.0:\n",
            "      Successfully uninstalled googleapis-common-protos-1.63.0\n",
            "  Attempting uninstall: attrs\n",
            "    Found existing installation: attrs 23.2.0\n",
            "    Uninstalling attrs-23.2.0:\n",
            "      Successfully uninstalled attrs-23.2.0\n",
            "  Attempting uninstall: jaxlib\n",
            "    Found existing installation: jaxlib 0.4.23+cuda12.cudnn89\n",
            "    Uninstalling jaxlib-0.4.23+cuda12.cudnn89:\n",
            "      Successfully uninstalled jaxlib-0.4.23+cuda12.cudnn89\n",
            "  Attempting uninstall: jax\n",
            "    Found existing installation: jax 0.4.23\n",
            "    Uninstalling jax-0.4.23:\n",
            "      Successfully uninstalled jax-0.4.23\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.2.0\n",
            "    Uninstalling google-auth-oauthlib-1.2.0:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.2.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.15.2\n",
            "    Uninstalling tensorboard-2.15.2:\n",
            "      Successfully uninstalled tensorboard-2.15.2\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.15.0\n",
            "    Uninstalling tensorflow-2.15.0:\n",
            "      Successfully uninstalled tensorflow-2.15.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "chex 0.1.86 requires jax>=0.4.16, but you have jax 0.4.14 which is incompatible.\n",
            "flax 0.8.2 requires jax>=0.4.19, but you have jax 0.4.14 which is incompatible.\n",
            "google-colab 1.0.0 requires portpicker==1.5.2, but you have portpicker 1.6.0 which is incompatible.\n",
            "ipython-sql 0.5.0 requires sqlalchemy>=2.0, but you have sqlalchemy 1.4.20 which is incompatible.\n",
            "pydantic 2.6.4 requires typing-extensions>=4.6.1, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "pydantic-core 2.16.3 requires typing-extensions!=4.7.0,>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "tf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.14.1 which is incompatible.\n",
            "torch 2.2.1+cu121 requires typing-extensions>=4.8.0, but you have typing-extensions 4.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed attrs-23.1.0 dp-accounting-0.4.3 farmhashpy-0.4.0 google-auth-oauthlib-1.0.0 google-vizier-0.1.11 googleapis-common-protos-1.61.0 grpcio-tools-1.48.2 jax-0.4.14 jaxlib-0.4.14 keras-2.14.0 packaging-22.0 portpicker-1.6.0 scipy-1.9.3 semantic-version-2.10.0 sqlalchemy-1.4.20 tensorboard-2.14.1 tensorflow-2.14.1 tensorflow-compression-2.14.0 tensorflow-estimator-2.14.0 tensorflow-federated-0.74.0 tensorflow-model-optimization-0.7.5 tensorflow-privacy-0.9.0 tensorflow-probability-0.22.1 typing-extensions-4.5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "portpicker"
                ]
              },
              "id": "29e703ec7ecd49d4ae85cb541e2cc0f2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.0/235.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "grpcio-tools 1.48.2 requires protobuf<4.0dev,>=3.12.0, but you have protobuf 4.25.3 which is incompatible.\n",
            "tensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 4.25.3 which is incompatible.\n",
            "tf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.14.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision\n",
        "!pip install tensorflow tensorflow-datasets tensorflow-federated\n",
        "!pip install -q flwr[simulation]\n",
        "\n",
        "from collections import OrderedDict\n",
        "from typing import Dict, List, Optional, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torchvision.datasets import EMNIST\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import tensorflow_federated as tff\n",
        "import tensorflow_datasets as tfds\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from math import comb\n",
        "from itertools import combinations\n",
        "from google.colab import drive\n",
        "import json\n",
        "from datetime import timedelta\n",
        "import time\n",
        "start = time.perf_counter()\n",
        "\n",
        "import flwr as fl\n",
        "from flwr.common import Metrics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Config"
      ],
      "metadata": {
        "id": "Dyk5O4ZcCSP0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mode = \"cuda\" # \"cuda\" to train on GPU\n",
        "DEVICE = torch.device(mode)\n",
        "print(\n",
        "    f\"Training on {DEVICE} using PyTorch {torch.__version__} and Flower {fl.__version__}\"\n",
        ")\n",
        "# Parameter Initialisation\n",
        "NUM_CLIENTS = 205\n",
        "LOCAL_EPOCHS = 5\n",
        "NUM_ROUNDS = 20\n",
        "BATCH_SIZE = 32\n",
        "SELECTION_RATE = 0.025 # what proportion of clients are selected per round\n",
        "SENSITIVE_ATTRIBUTES = [0,1,2,3,4,5,6,7,8,9] # a list of the numbers corresponding to sensitive classes\n",
        "# Preparing data structure for JSON export\n",
        "data = {\n",
        "    \"rounds\": [],\n",
        "    \"general_fairness\": {\n",
        "          \"f_j\": [],\n",
        "          \"f_g\": [],\n",
        "          \"f_r\": [],\n",
        "          \"f_o\": []},\n",
        "      \"config\": {\n",
        "          \"num_clients\": NUM_CLIENTS,\n",
        "          \"local_epochs\": LOCAL_EPOCHS,\n",
        "          \"num_rounds\": NUM_ROUNDS,\n",
        "          \"batch_size\": BATCH_SIZE,\n",
        "          \"selection_rate\": SELECTION_RATE,\n",
        "          \"sensitive_attributes\": SENSITIVE_ATTRIBUTES},\n",
        "      \"per_client_data\": {\n",
        "            \"shap\": [],\n",
        "            \"accuracy\": [],\n",
        "            \"avg_eop\": [],\n",
        "            \"gains\": []}}\n",
        "# Setting up for Data Storage:\n",
        "drive.mount('/content/drive')\n",
        "path_extension = f'FedAvg_FEMNIST_iid_{NUM_CLIENTS}C_{int(SELECTION_RATE * 100)}PC_{LOCAL_EPOCHS}E_{NUM_ROUNDS}R_v2'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvKKWZntCSaM",
        "outputId": "29c02e8f-5929-49cd-9354-799e58765163"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on cuda using PyTorch 2.2.1+cu121 and Flower 1.7.0\n",
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjO_GmGq9JY4"
      },
      "source": [
        "### Data Loading\n",
        "Beginning with CIFAR-10, loading the data across NUM_CLIENTS. The function load_datasets(...) will partition the database for the number of clients selected. See the following links that are useful for deployment. Using the tensorflow federated EMNIST dataset and converting to torch data objects.\n",
        "\n",
        "https://flower.ai/docs/datasets/tutorial-quickstart.html\n",
        "\n",
        "https://www.tensorflow.org/federated/tutorials/loading_remote_data\n",
        "\n",
        "https://github.com/TalwalkarLab/leaf/tree/master/data/femnist\n",
        "\n",
        "https://www.tensorflow.org/federated/api_docs/python/tff/simulation/datasets/ClientData\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywqDqMVA9gwB"
      },
      "outputs": [],
      "source": [
        "def load_datasets(num_clients: int):\n",
        "    # Loading and processing the FEMNIST dataset for the non-iid setting.\n",
        "    # Use this maths to determine the number we need to sample for test set\n",
        "    # Normal is 671,585: 77,483 train:test for 3400 clients\n",
        "    # Average number of train per client is 197.525\n",
        "    # Average number of val per client is 22.789\n",
        "    # Total number of samples per client is 230.3\n",
        "    # 205/3400 = 0.0602941, therefore 0.0602941(671585) = 40492.625 train samples\n",
        "    # 0.0602941(77483) = 4671.7677503 train samples hence 45164.392 total distributed\n",
        "    # To maintain the same train to test ratios, 45164.392*(77483/671585) = 5210.766 test\n",
        "    # Number of clients for test = 5210.766 / 22.789 = 228.65 clients from the test to samples\n",
        "    train_length = 198 # Proportions based on the average division used in the niid case.\n",
        "    val_length = 23\n",
        "    test_set_size = int(NUM_CLIENTS*(((NUM_CLIENTS / 3400) * (671585 + 77483) * (77483 / 671585)) / (77483 / 3400)))\n",
        "    trainset, testset = tff.simulation.datasets.emnist.load_data(only_digits=False, cache_dir=None)\n",
        "    trainset = list(tfds.as_numpy(testset.create_tf_dataset_from_all_clients()))\n",
        "    testset = list(tfds.as_numpy(testset.create_tf_dataset_from_all_clients()))\n",
        "    partition_size = train_length + val_length # to achieve the same average number of samples per client as the niid setting\n",
        "    lengths = [partition_size] * num_clients\n",
        "    lengths.append(len(trainset) - int(np.sum(np.array(lengths))))\n",
        "    datasets = random_split(trainset, lengths, torch.Generator().manual_seed(42)) # manual seed defines the pseudo random generator\n",
        "    testset = random_split(testset, [test_set_size, (len(testset) - test_set_size)], torch.Generator().manual_seed(42))\n",
        "    trainloaders = []\n",
        "    valloaders = []\n",
        "    for i in range(len(datasets) - 1):\n",
        "        ds = datasets[i]\n",
        "        len_val = len(ds) // (train_length / val_length)  # 10 % validation set\n",
        "        len_train = len(ds) - len_val\n",
        "        lengths = [int(len_train), int(len_val)]\n",
        "        ds_train, ds_val = random_split(ds, lengths, torch.Generator().manual_seed(42))\n",
        "        trainloaders.append(DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True, drop_last=False))\n",
        "        valloaders.append(DataLoader(ds_val, batch_size=BATCH_SIZE, shuffle=True))\n",
        "    testloader = DataLoader(testset[0], batch_size=BATCH_SIZE, drop_last=False)\n",
        "    # print(f\"Length of trainloaders = {len(trainloaders)}, Length of valloaders = {len(valloaders)}\")\n",
        "    # for i in range(NUM_CLIENTS):\n",
        "    #     print(f\"Client {i} has trainloader length = {len(trainloaders[i])} batches of {NUM_BATCHES}\")\n",
        "    #     print(f\"Client {i} has valloader length = {len(valloaders[i])} batches of {NUM_BATCHES}\")\n",
        "    # # Visualising the dataset\n",
        "    # batch = next(iter(trainloaders[0]))\n",
        "    # images, labels = batch['pixels'], batch['label']\n",
        "    emnist_labels = {0: '0',1: '1',2: '2',3: '3',4: '4',5: '5',6: '6',7: '7',8: '8',9: '9',10: 'A',\n",
        "    11: 'B',12: 'C',13: 'D',14: 'E',15: 'F',16: 'G',17: 'H',18: 'I',19: 'J',20: 'K',21: 'L',22: 'M',\n",
        "    23: 'N',24: 'O',25: 'P',26: 'Q',27: 'R',28: 'S',29: 'T',30: 'U',31: 'V',32: 'W',33: 'X',34: 'Y',\n",
        "    35: 'Z',36: 'a',37: 'b',38: 'c',39: 'd',40: 'e',41: 'f',42: 'g',43: 'h',44: 'i',45: 'j',46: 'k',47: 'l',\n",
        "    48: 'm',49: 'n',50: 'o',51: 'p',52: 'q',53: 'r',54: 's',55: 't',56: 'u',57: 'v',58: 'w',59: 'x',60: 'y',61: 'z'}\n",
        "    # Use the following to visualise the data:\n",
        "    # fig, axs = plt.subplots(4,8,figsize=(12,6))\n",
        "    # print(\"A trainloader sample:\")\n",
        "    # for i, ax in enumerate(axs.flat):\n",
        "    #   ax.imshow(images[i], cmap='gray')\n",
        "    #   ax.set_title(emnist_labels[int(labels[i])])\n",
        "    #   ax.axis(\"off\")\n",
        "    # plt.tight_layout()\n",
        "    # plt.show()\n",
        "    # # Investigating the test set\n",
        "    # print(\"A Testloader sample\")\n",
        "    # batch = next(iter(testloader))\n",
        "    # images, labels = batch['pixels'], batch['label']\n",
        "    # fig, axs = plt.subplots(4,8,figsize=(12,6))\n",
        "    # for i, ax in enumerate(axs.flat):\n",
        "    #   ax.imshow(images[i], cmap='gray')\n",
        "    #   ax.set_title(emnist_labels[int(labels[i])])\n",
        "    #   ax.axis(\"off\")\n",
        "    # plt.tight_layout()\n",
        "    # plt.show()\n",
        "    return trainloaders, valloaders, testloader, emnist_labels.values()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdxbcaDU9mD0"
      },
      "source": [
        "### Training/ Evaluation\n",
        "We need the get(...) and the set(...) functions for moving model parameters to and from the clients and between Numpy ndarrays which flower can operate on.\n",
        "\n",
        "Adapted from the basic skeleton of the Flower tutorial: https://flower.ai/docs/framework/tutorial-series-use-a-federated-learning-strategy-pytorch.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RusS4i-39taT"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super(Net, self).__init__() # Calls init method of Net superclass (nn.Module) enabling access to nn\n",
        "        self.fmaps1 = 40\n",
        "        self.fmaps2 = 160\n",
        "        self.dense = 200\n",
        "        self.dropout = 0.4\n",
        "        self.batch_size = 32\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=self.fmaps1, kernel_size=5, stride=1, padding='same'),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=self.fmaps1, out_channels=self.fmaps2, kernel_size=5, stride=1, padding='same'),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "        )\n",
        "        self.fcon1 = nn.Sequential(nn.Linear(49*self.fmaps2, self.dense), nn.LeakyReLU())\n",
        "        self.fcon2 = nn.Linear(self.dense, 62)\n",
        "        self.dropout = nn.Dropout(p=self.dropout)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor: # -> is an annotation for function output\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.dropout(self.fcon1(x))\n",
        "        x = self.fcon2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def get_parameters(net) -> List[np.ndarray]:\n",
        "    # taking state_dict values to numpy (state_dict holds learnable parameters)\n",
        "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
        "\n",
        "\n",
        "def set_parameters(net, parameters: List[np.ndarray]):\n",
        "    # Setting the new parameters in the state_dict from numpy that flower operated on\n",
        "    params_dict = zip(net.state_dict().keys(), parameters)\n",
        "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "    net.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "def train(net, trainloader, epochs: int):\n",
        "    \"\"\"Train the network on the training set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(net.parameters())\n",
        "    net.train()\n",
        "    for epoch in range(epochs):\n",
        "        correct, total, epoch_loss = 0, 0, 0.0\n",
        "        for batch in trainloader:\n",
        "            images = batch['pixels']\n",
        "            labels = batch['label']\n",
        "            length = len(images)\n",
        "            images = torch.reshape(images, (length, 1, 28, 28)) # required to meet NN input shape\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(images)\n",
        "            loss = criterion(net(images), labels.long())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            # Metrics\n",
        "            epoch_loss += loss\n",
        "            total += length\n",
        "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
        "        epoch_loss /= len(trainloader.dataset)\n",
        "        epoch_acc = correct / total\n",
        "        print(f\"Epoch {epoch+1}: train loss {epoch_loss}, accuracy {epoch_acc}\")\n",
        "\n",
        "\n",
        "def test(net, testloader, sensitive_labels=[]):\n",
        "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    correct, total, loss = 0, 0, 0.0\n",
        "    group_performance = [[0,0] for label in range(len(sensitive_labels))] # preset for EOP calc, will store the performance\n",
        "    # init array for storing EOP information\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in testloader:\n",
        "            images = batch['pixels']\n",
        "            labels = batch['label']\n",
        "            length = len(images)\n",
        "            images = torch.reshape(images, (length, 1, 28, 28)) # required to meet NN input shape\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            outputs = net(images)\n",
        "            loss += criterion(outputs, labels.long()).item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            # Comparing the predicted to the inputs in order to determine EOP\n",
        "            matched = (predicted == labels)\n",
        "            for label in range(len(sensitive_labels)):\n",
        "              labelled = (labels == label)\n",
        "              not_labelled = (labels != label)\n",
        "              group_performance[label][0] += (matched == labelled).sum() # issue is that it will log it correctly if both were wrong\n",
        "              group_performance[label][1] += (matched == not_labelled).sum()\n",
        "            total += length\n",
        "            correct += matched.sum().item()\n",
        "    for index in range(len(group_performance)):\n",
        "      # Calculating P(Y.=1|A=1,Y=1) - P(Y.=1|A=0,Y=1) for each:\n",
        "      # NB: could expand EOP to EOD by accounting for all results not just the correct results, seeing if predictions match\n",
        "        group_performance[index] = float((group_performance[index][0] - group_performance[index][1]) / total)\n",
        "    loss /= len(testloader.dataset)\n",
        "    accuracy = correct / total\n",
        "    return loss, accuracy, group_performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFKEvxhH9v2K"
      },
      "source": [
        "### Creating the Flower Client\n",
        "We pass in cid for additional logging."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gbOjVkUq-ns8"
      },
      "outputs": [],
      "source": [
        "class FlowerClient(fl.client.NumPyClient):\n",
        "    def __init__(self, cid, net, trainloader, valloader):\n",
        "        self.cid = cid\n",
        "        self.net = net\n",
        "        self.trainloader = trainloader\n",
        "        self.valloader = valloader\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        print(f\"[Client {self.cid}] get_parameters\")\n",
        "        return get_parameters(self.net)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        # The training method for the client\n",
        "        # Need to use the config dictionary in order to\n",
        "        server_round = config[\"server_round\"]\n",
        "        local_epochs = config[\"local_epochs\"]\n",
        "        sensitive_attributes = config[\"sensitive_attributes\"]\n",
        "        print(f\"[Client {self.cid}, round {server_round}] fit, config: {config}\")\n",
        "        set_parameters(self.net, parameters)\n",
        "        _, reward, _ = test(self.net, self.valloader, []) # The reward is defined as the accuracy of the model on the central data\n",
        "        train(self.net, self.trainloader, epochs=local_epochs)\n",
        "        # Performing federated evaluation on the clients that are sampled for training:\n",
        "        print(f\"[Client {self.cid}] evaluate, config: {config}\")\n",
        "        set_parameters(self.net, get_parameters(self.net)) # getting end of training round accuracy\n",
        "        loss, accuracy, group_eod = test(self.net, self.valloader, sensitive_attributes)\n",
        "        # Need to process the EOD data here to determine group fairness:\n",
        "        group_fairness = dict(zip(sensitive_attributes, group_eod))\n",
        "        # Can include enhanced processing to show which groups are not performing well (eop's further from zero)\n",
        "        return get_parameters(self.net), len(self.trainloader), {\"cid\":int(self.cid), \"parameters\": get_parameters(self.net), \"accuracy\": float(accuracy), \"loss\": float(loss), \"group_fairness\": group_fairness, \"reward\": float(reward)}\n",
        "\n",
        "\n",
        "def client_fn(cid) -> FlowerClient:\n",
        "    # Instances of clients are only created when required to avoid depleting RAM.\n",
        "    net = Net().to(DEVICE)\n",
        "    trainloader = trainloaders[int(cid)]\n",
        "    valloader = valloaders[int(cid)]\n",
        "    return FlowerClient(cid, net, trainloader, valloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSEF7A4tUxU3"
      },
      "source": [
        "### Customisation\n",
        "Using the config dictionary to alter client behaviour."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fipo7xazUxe9"
      },
      "outputs": [],
      "source": [
        "def fit_config(server_round: int):\n",
        "    \"\"\"Return training configuration dict for each round.\n",
        "    \"\"\"\n",
        "    config = {\n",
        "        \"server_round\": server_round,  # The current round of federated learning\n",
        "        \"local_epochs\": LOCAL_EPOCHS,\n",
        "        \"sensitive_attributes\": SENSITIVE_ATTRIBUTES,\n",
        "    }\n",
        "    return config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lApH1qmU5BgI"
      },
      "source": [
        "### Shapley Values\n",
        "First attempt at implementing the Shapley calculations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TvuLaTo15BmV"
      },
      "outputs": [],
      "source": [
        "class Shapley():\n",
        "  \"\"\"\n",
        "  Implementation of the different types of the Federated Shapley value.\n",
        "  \"\"\"\n",
        "  def __init__(self, test_set, test_function, set_parameters, number_clients: int):\n",
        "    self.dataset = test_set\n",
        "    self.test = test\n",
        "    self.set_parameters = set_parameters\n",
        "    self.num_clients = number_clients\n",
        "    self.resultsFedSV = np.zeros(NUM_CLIENTS) # Holding the FedSV Shapley values indexed by client id\n",
        "    self.aggregatedRoundParams = None # if required we can use: fl.common.ndarrays_to_parameters(get_parameters(Net()))\n",
        "    self.centralLoss = 0 # Taken from the centralised evaluation as it is not necessary to compute twice\n",
        "    self.round = 0 # Auto updated by the evaluation function for debugging\n",
        "    self.f_o = 0\n",
        "    self.net = Net().to(DEVICE)\n",
        "    return\n",
        "\n",
        "  def __utility_function(self, comparitive_weights):#: List[fl.common.NDArrays]):\n",
        "    \"\"\"\n",
        "    Per round utility function.\n",
        "    Input: array of model weights, if a nested array then average of the set's\n",
        "           weights obtained.\n",
        "    Output: the difference in the loss between the aggregated weights for the round\n",
        "            and the average of the input set of weights.\n",
        "    \"\"\"\n",
        "    # Perform an average on the comparitive weights\n",
        "    set_size = len(comparitive_weights)\n",
        "    if set_size == 1:\n",
        "      alt_weights = comparitive_weights[0]\n",
        "    else:\n",
        "      alt_weights = np.mean([np.array(weights, dtype=object) for weights in comparitive_weights], axis=0)\n",
        "    # Initialising a test net to compare to the centrally evaluated loss.\n",
        "    self.set_parameters(self.net, list(alt_weights)) # issue with alt_weights averaging\n",
        "    loss, _, _ = self.test(self.net, self.dataset) # Testing on the central dataset\n",
        "    return float(self.centralLoss - loss)\n",
        "\n",
        "  def __power_set(self, input_set):\n",
        "    \"\"\"\n",
        "    Returns the improper power set of the input set, the empty set is removed as\n",
        "    it does not make sense to train a model on zero weights\n",
        "    \"\"\"\n",
        "    input_list = list(input_set)\n",
        "    power_set =  [list(c) for r in range(len(input_list) + 1) for c in combinations(input_list, r)]\n",
        "    return power_set[1:]\n",
        "\n",
        "  def fedSV(self, round_participants,\n",
        "            participant_weights: List[fl.common.NDArrays]):\n",
        "    \"\"\"\n",
        "    Calculating the original federated Shapley value.\n",
        "    Method is called each round when the training has been completed and the\n",
        "    server has aggregated parameters to form the new model.\n",
        "    \"\"\"\n",
        "    # NOTE - big issues around central dataset assumption - needs to be iid\n",
        "    # and representative etc - all that I didn't want to have to do\n",
        "    print(f\"Calculating the round {self.round} Shapley values\")\n",
        "    for i in range(self.num_clients):\n",
        "      # if the client has not participated in training, skip, it is assigned\n",
        "      # a Shapley value of zero for that round:\n",
        "      if i not in round_participants:\n",
        "        continue\n",
        "      else:\n",
        "        # find the power set - all the subsets without client i\n",
        "        contributions = 0\n",
        "        s_t = 0\n",
        "        set_without_i = round_participants.copy()\n",
        "        set_without_i.remove(i)\n",
        "        #print(f\"We find the power set of {round_participants} without {i} which is {set_without_i}\")\n",
        "        power_set = self.__power_set(set_without_i)\n",
        "        power_weights = [[participant_weights[j] for j in s] for s in power_set]\n",
        "        for s in power_weights:\n",
        "          without_i = self.__utility_function(s)\n",
        "          t = s.copy()\n",
        "          t.append(participant_weights[i])\n",
        "          with_i = self.__utility_function(t)\n",
        "          # We accumulate the contributions from each client for each round:\n",
        "          contributions += (1 / comb(len(round_participants)-1,len(s))) * (with_i - without_i)\n",
        "        s_t = contributions / len(round_participants)\n",
        "        print(f\"Client {i} has Shapley contribution {s_t}\")\n",
        "        self.resultsFedSV[i] = self.resultsFedSV[i] + s_t # updating the Shapley value\n",
        "    return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnctYYnLRWJb"
      },
      "source": [
        "### Evaluation Metrics\n",
        "Passing a custom function into the strategy, it will call the function whenever it receives an evaluation metric dictionaries from the client. The evaluate function in the client has performed **federated evaluation** and we use this data to post the average accuracy. The aim is to expand this function and the client evalation method in order to calculate our fairness metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tjkFkdgER7CK"
      },
      "outputs": [],
      "source": [
        "def evaluate(server_round: int,\n",
        "             parameters: fl.common.NDArrays,\n",
        "             config: Dict[str, fl.common.Scalar]) -> Optional[Tuple[float, Dict[str, fl.common.Scalar]]]:\n",
        "             # Used for centralised evaluation. This is enacted by flower before the Federated Evaluation.\n",
        "             # Runs initially before FL begins as well.\n",
        "    net = Net().to(DEVICE)\n",
        "    shap.aggregatedRoundParams = parameters\n",
        "    set_parameters(net, parameters)\n",
        "    loss, accuracy, _ = test(net, testloader)\n",
        "    shap.f_o = accuracy\n",
        "    shap.centralLoss = loss\n",
        "    shap.round = server_round\n",
        "    print(f\"Server-side evaluation loss {loss} / accuracy {accuracy}\")\n",
        "    return loss, {\"accuracy\": accuracy}\n",
        "\n",
        "\n",
        "def fit_callback(metrics: List[Tuple[int, Metrics]]) -> Metrics:\n",
        "    # Called at the end of the clients fit method\n",
        "    # Used to call the Shapley calculation as it is before weight aggregation\n",
        "    clients = set()\n",
        "    parameters = [None for client in range(NUM_CLIENTS)]\n",
        "    # Why are the parameters we get here the post aggregation ones...?\n",
        "    for client in metrics:\n",
        "      cid = client[1][\"cid\"]\n",
        "      clients.add(cid)\n",
        "      parameters[cid] = client[1][\"parameters\"]\n",
        "    if True:\n",
        "      shap.fedSV(clients, parameters)\n",
        "    # Jain's fairness index (JFI) is used to evaluate uniformity for the fairness metrics\n",
        "    JFI = lambda x: ((np.sum(x)**2) / (len(x) * np.sum(x**2)))\n",
        "    # We determine individual fairness using the FedEval accuracy and JFI\n",
        "    accuracies = np.array([metric[\"accuracy\"] for _,metric in metrics])\n",
        "    rewards = np.array([metric[\"reward\"] for _,metric in metrics])\n",
        "    contributions = shap.resultsFedSV\n",
        "    gains = np.array([accuracies[i] / contributions[metrics[i][1][\"cid\"]] for i in range(len(metrics))])\n",
        "    f_j = JFI(gains)\n",
        "    print(f\"Individual fairness, f_j = {f_j}\")\n",
        "    # As we have passed the sensitive labels into fedEval, we calculate f_g\n",
        "    group_fairness = np.array([metric[\"group_fairness\"] for _,metric in metrics])\n",
        "    # Linear mapping the average EOD which is between [-1,1] to [0,1] by taking mod (this is okay as either are unfair just represents difference in false )\n",
        "    f_g = 1 - np.mean(np.median(np.absolute(np.array([np.mean(np.array(list(group_dict.values()))) for group_dict in group_fairness]))))\n",
        "    print(f\"Group fairness, f_g = {f_g}\")\n",
        "    # We calculate incentive fairness using the reward (accuracy) and contributions\n",
        "    # We only get accuracies of the evaluated client set, we match the contribution by cid\n",
        "    reward_gains = np.array([rewards[i] / contributions[metrics[i][1][\"cid\"]] for i in range(len(metrics))])\n",
        "    if np.sum(reward_gains) == 0: # Used to catch the case where the accuracy is zero for all clients which would break JFI\n",
        "      f_r = 1 # if all are zero, it is technically uniform\n",
        "    else:\n",
        "      f_r = JFI(reward_gains)\n",
        "    print(f\"Incentive fairness, f_r = {f_r}\")\n",
        "    # Obtain the orchestrator fairness back from the Shapley class\n",
        "    # f_o = shap.f_o # centralised evaluation option\n",
        "    f_o = np.mean(accuracies)\n",
        "    print(f\"Orchestrator fairness, f_o = {f_o}\")\n",
        "    # Saving metrics to dictionary for JSON storage:\n",
        "    data[\"rounds\"].append(shap.round)\n",
        "    data[\"general_fairness\"][\"f_j\"].append(f_j)\n",
        "    data[\"general_fairness\"][\"f_g\"].append(f_g)\n",
        "    data[\"general_fairness\"][\"f_r\"].append(f_r)\n",
        "    data[\"general_fairness\"][\"f_o\"].append(f_o)\n",
        "    data[\"per_client_data\"][\"shap\"].append(list(contributions))\n",
        "    data[\"per_client_data\"][\"accuracy\"].append(list(accuracies))\n",
        "    data[\"per_client_data\"][\"avg_eop\"].append(list(group_fairness))\n",
        "    data[\"per_client_data\"][\"gains\"].append(list(gains))\n",
        "\n",
        "    return {\"f_j\": f_j, \"f_g\": f_g, \"f_r\": f_r, \"f_o\": f_o}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aclmrXq-qYk"
      },
      "source": [
        "### Strategy Customisation\n",
        "In many cases, we want more control over parameter initialisation for the global model (which defaults to initialising the global model by asking one random client for the initial parameters). We pass initial parameters directly to the strategy.\n",
        "\n",
        "Docs for strategies: https://flower.dev/docs/framework/how-to-implement-strategies.html\n",
        "\n",
        "The strategy defines the approach we are using and it is passed to the start simulation function."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Gathering the data:\n",
        "import pickle\n",
        "trainloaders, valloaders, testloader, text_labels = load_datasets(NUM_CLIENTS)\n",
        "data = {\"train\": trainloaders,\n",
        "        \"val\": valloaders,\n",
        "        \"test\": testloader,\n",
        "        \"labels\": list(text_labels)}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wcwg6aWPZlKg",
        "outputId": "95186541-e9fc-4a5c-9630-0dae2b55e961"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/My Drive/FL/Results/'+ 'femnist_iid_loaded' + '.pickle', \"wb\") as outfile:\n",
        "    pickle.dump(data, outfile)"
      ],
      "metadata": {
        "id": "SI5Yo1v_cjaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rnDFJJvSBw0V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ed66b37-982c-4fbb-a7ca-be6b96a8f5f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading emnist_all.sqlite.lzma: 100%|██████████| 170507172/170507172 [00:46<00:00, 3686252.74it/s]\n",
            "INFO flwr 2024-03-20 10:52:35,086 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=20, round_timeout=None)\n",
            "INFO:flwr:Starting Flower simulation, config: ServerConfig(num_rounds=20, round_timeout=None)\n",
            "2024-03-20 10:52:38,671\tINFO worker.py:1621 -- Started a local Ray instance.\n",
            "INFO flwr 2024-03-20 10:52:40,947 | app.py:213 | Flower VCE: Ray initialized with resources: {'accelerator_type:V100': 1.0, 'memory': 7864929486.0, 'object_store_memory': 3932464742.0, 'node:172.28.0.12': 1.0, 'GPU': 1.0, 'CPU': 2.0, 'node:__internal_head__': 1.0}\n",
            "INFO:flwr:Flower VCE: Ray initialized with resources: {'accelerator_type:V100': 1.0, 'memory': 7864929486.0, 'object_store_memory': 3932464742.0, 'node:172.28.0.12': 1.0, 'GPU': 1.0, 'CPU': 2.0, 'node:__internal_head__': 1.0}\n",
            "INFO flwr 2024-03-20 10:52:40,955 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html\n",
            "INFO:flwr:Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html\n",
            "INFO flwr 2024-03-20 10:52:40,959 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 1.0}\n",
            "INFO:flwr:Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 1.0}\n",
            "INFO flwr 2024-03-20 10:52:41,030 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 1 actors\n",
            "INFO:flwr:Flower VCE: Creating VirtualClientEngineActorPool with 1 actors\n",
            "INFO flwr 2024-03-20 10:52:41,043 | server.py:89 | Initializing global parameters\n",
            "INFO:flwr:Initializing global parameters\n",
            "INFO flwr 2024-03-20 10:52:41,052 | server.py:272 | Using initial parameters provided by strategy\n",
            "INFO:flwr:Using initial parameters provided by strategy\n",
            "INFO flwr 2024-03-20 10:52:41,068 | server.py:91 | Evaluating initial parameters\n",
            "INFO:flwr:Evaluating initial parameters\n",
            "INFO flwr 2024-03-20 10:52:45,320 | server.py:94 | initial parameters (loss, other metrics): 0.12916205187897586, {'accuracy': 0.005546903334542274}\n",
            "INFO:flwr:initial parameters (loss, other metrics): 0.12916205187897586, {'accuracy': 0.005546903334542274}\n",
            "INFO flwr 2024-03-20 10:52:45,323 | server.py:104 | FL starting\n",
            "INFO:flwr:FL starting\n",
            "DEBUG flwr 2024-03-20 10:52:45,327 | server.py:222 | fit_round 1: strategy sampled 5 clients (out of 205)\n",
            "DEBUG:flwr:fit_round 1: strategy sampled 5 clients (out of 205)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Server-side evaluation loss 0.12916205187897586 / accuracy 0.005546903334542274\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=10387)\u001b[0m 2024-03-20 10:52:45.560689: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=10387)\u001b[0m 2024-03-20 10:52:45.560761: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=10387)\u001b[0m 2024-03-20 10:52:45.560817: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=10387)\u001b[0m 2024-03-20 10:52:48.101981: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m /usr/local/lib/python3.10/dist-packages/flwr/simulation/ray_transport/ray_actor.py:72: DeprecationWarning:  Ensure your client is of type `flwr.client.Client`. Please convert it using the `.to_client()` method before returning it in the `client_fn` you pass to `start_simulation`. We have applied this conversion on your behalf. Not returning a `Client` might trigger an error in future versions of Flower.\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m   client = check_clientfn_returns_client(client_fn(cid))\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 128, round 1] fit, config: {'server_round': 1, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.14488454163074493, accuracy 0.03571428571428571\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.13532094657421112, accuracy 0.07142857142857142\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.13677901029586792, accuracy 0.07142857142857142\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.1358821988105774, accuracy 0.04081632653061224\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.13094434142112732, accuracy 0.07653061224489796\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 128] evaluate, config: {'server_round': 1, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m /usr/local/lib/python3.10/dist-packages/flwr/simulation/ray_transport/ray_actor.py:72: DeprecationWarning:  Ensure your client is of type `flwr.client.Client`. Please convert it using the `.to_client()` method before returning it in the `client_fn` you pass to `start_simulation`. We have applied this conversion on your behalf. Not returning a `Client` might trigger an error in future versions of Flower.\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m   client = check_clientfn_returns_client(client_fn(cid))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 67, round 1] fit, config: {'server_round': 1, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.14716213941574097, accuracy 0.030612244897959183\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.14050695300102234, accuracy 0.061224489795918366\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.13380765914916992, accuracy 0.061224489795918366\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.13321001827716827, accuracy 0.061224489795918366\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.13361746072769165, accuracy 0.061224489795918366\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 67] evaluate, config: {'server_round': 1, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 95, round 1] fit, config: {'server_round': 1, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.1459856629371643, accuracy 0.03571428571428571\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.13945868611335754, accuracy 0.04591836734693878\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.13345904648303986, accuracy 0.0663265306122449\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.13220414519309998, accuracy 0.061224489795918366\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.13456736505031586, accuracy 0.05102040816326531\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 95] evaluate, config: {'server_round': 1, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 32, round 1] fit, config: {'server_round': 1, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.143923819065094, accuracy 0.03571428571428571\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.1406075358390808, accuracy 0.0663265306122449\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.13395380973815918, accuracy 0.061224489795918366\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.1330072581768036, accuracy 0.07653061224489796\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.13121452927589417, accuracy 0.07142857142857142\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 32] evaluate, config: {'server_round': 1, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-03-20 10:53:08,193 | server.py:236 | fit_round 1 received 5 results and 0 failures\n",
            "DEBUG:flwr:fit_round 1 received 5 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 62, round 1] fit, config: {'server_round': 1, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.14179418981075287, accuracy 0.03571428571428571\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.13764168322086334, accuracy 0.04081632653061224\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.13461366295814514, accuracy 0.04081632653061224\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.13251785933971405, accuracy 0.07142857142857142\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.13071897625923157, accuracy 0.09693877551020408\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 62] evaluate, config: {'server_round': 1, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "Calculating the round 0 Shapley values\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-ae50859afb71>:40: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
            "  state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client 32 has Shapley contribution -0.0015482601108830032\n",
            "Client 62 has Shapley contribution -0.0007163351067661248\n",
            "Client 67 has Shapley contribution -0.0013409480216334134\n",
            "Client 95 has Shapley contribution -0.0013116632419777658\n",
            "Client 128 has Shapley contribution -0.0008921297201021338\n",
            "Individual fairness, f_j = 0.7599797810426164\n",
            "Group fairness, f_g = 0.18400002121925352\n",
            "Incentive fairness, f_r = nan\n",
            "Orchestrator fairness, f_o = 0.048\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-c14e40a9251f>:30: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  JFI = lambda x: ((np.sum(x)**2) / (len(x) * np.sum(x**2)))\n",
            "INFO flwr 2024-03-20 10:57:42,338 | server.py:125 | fit progress: (1, 0.12440716528799435, {'accuracy': 0.05179954344718708}, 297.01081743899977)\n",
            "INFO:flwr:fit progress: (1, 0.12440716528799435, {'accuracy': 0.05179954344718708}, 297.01081743899977)\n",
            "INFO flwr 2024-03-20 10:57:42,343 | server.py:171 | evaluate_round 1: no clients selected, cancel\n",
            "INFO:flwr:evaluate_round 1: no clients selected, cancel\n",
            "DEBUG flwr 2024-03-20 10:57:42,350 | server.py:222 | fit_round 2: strategy sampled 5 clients (out of 205)\n",
            "DEBUG:flwr:fit_round 2: strategy sampled 5 clients (out of 205)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Server-side evaluation loss 0.12440716528799435 / accuracy 0.05179954344718708\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 153, round 2] fit, config: {'server_round': 2, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.13687007129192352, accuracy 0.04591836734693878\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.128703773021698, accuracy 0.07653061224489796\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.12527191638946533, accuracy 0.07142857142857142\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.12150228768587112, accuracy 0.10204081632653061\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.11696939915418625, accuracy 0.09693877551020408\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 153] evaluate, config: {'server_round': 2, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 50, round 2] fit, config: {'server_round': 2, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.13594360649585724, accuracy 0.015306122448979591\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.13231691718101501, accuracy 0.08163265306122448\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.12910699844360352, accuracy 0.05102040816326531\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.1316925585269928, accuracy 0.030612244897959183\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.1350799798965454, accuracy 0.11734693877551021\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 50] evaluate, config: {'server_round': 2, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 141, round 2] fit, config: {'server_round': 2, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.13974344730377197, accuracy 0.04591836734693878\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.12972229719161987, accuracy 0.0663265306122449\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.12959285080432892, accuracy 0.08163265306122448\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.12803877890110016, accuracy 0.07142857142857142\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.13135108351707458, accuracy 0.09183673469387756\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 141] evaluate, config: {'server_round': 2, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 94, round 2] fit, config: {'server_round': 2, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.13473033905029297, accuracy 0.05102040816326531\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.13474123179912567, accuracy 0.05102040816326531\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.13068273663520813, accuracy 0.05102040816326531\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.13367502391338348, accuracy 0.0663265306122449\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.13149124383926392, accuracy 0.061224489795918366\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 94] evaluate, config: {'server_round': 2, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-03-20 10:57:56,991 | server.py:236 | fit_round 2 received 5 results and 0 failures\n",
            "DEBUG:flwr:fit_round 2 received 5 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 91, round 2] fit, config: {'server_round': 2, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.1397201120853424, accuracy 0.02040816326530612\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.1350373774766922, accuracy 0.0663265306122449\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.12852558493614197, accuracy 0.061224489795918366\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.12952429056167603, accuracy 0.05102040816326531\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.127192422747612, accuracy 0.061224489795918366\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 91] evaluate, config: {'server_round': 2, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "Calculating the round 1 Shapley values\n",
            "Client 50 has Shapley contribution 0.0009140096933272915\n",
            "Client 91 has Shapley contribution 3.798292918177468e-05\n",
            "Client 94 has Shapley contribution 0.0006133134099957485\n",
            "Client 141 has Shapley contribution 0.0006376131795434842\n",
            "Client 153 has Shapley contribution 0.0008832102048451252\n",
            "Individual fairness, f_j = 0.3328334485251469\n",
            "Group fairness, f_g = 0.2880000174045563\n",
            "Incentive fairness, f_r = 0.2465727158639456\n",
            "Orchestrator fairness, f_o = 0.11200000000000002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2024-03-20 11:02:29,953 | server.py:125 | fit progress: (2, 0.11417746463517893, {'accuracy': 0.12260789793697864}, 584.626626752)\n",
            "INFO:flwr:fit progress: (2, 0.11417746463517893, {'accuracy': 0.12260789793697864}, 584.626626752)\n",
            "INFO flwr 2024-03-20 11:02:29,957 | server.py:171 | evaluate_round 2: no clients selected, cancel\n",
            "INFO:flwr:evaluate_round 2: no clients selected, cancel\n",
            "DEBUG flwr 2024-03-20 11:02:29,961 | server.py:222 | fit_round 3: strategy sampled 5 clients (out of 205)\n",
            "DEBUG:flwr:fit_round 3: strategy sampled 5 clients (out of 205)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Server-side evaluation loss 0.11417746463517893 / accuracy 0.12260789793697864\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 90, round 3] fit, config: {'server_round': 3, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.13057473301887512, accuracy 0.08673469387755102\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.12520331144332886, accuracy 0.10204081632653061\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.11847403645515442, accuracy 0.1377551020408163\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.11814741790294647, accuracy 0.10714285714285714\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.11483805626630783, accuracy 0.1989795918367347\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 90] evaluate, config: {'server_round': 3, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 82, round 3] fit, config: {'server_round': 3, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.12929673492908478, accuracy 0.08163265306122448\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.1232919991016388, accuracy 0.12755102040816327\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.122120201587677, accuracy 0.20408163265306123\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.11676447838544846, accuracy 0.20408163265306123\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.10220913589000702, accuracy 0.25\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 82] evaluate, config: {'server_round': 3, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 153, round 3] fit, config: {'server_round': 3, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.1212477833032608, accuracy 0.09183673469387756\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.12207368016242981, accuracy 0.14795918367346939\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.11205952614545822, accuracy 0.21428571428571427\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.10741069167852402, accuracy 0.2193877551020408\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.09824477881193161, accuracy 0.3010204081632653\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 153] evaluate, config: {'server_round': 3, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 18, round 3] fit, config: {'server_round': 3, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.1319100707769394, accuracy 0.08673469387755102\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.12742261588573456, accuracy 0.11224489795918367\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.1196671798825264, accuracy 0.15816326530612246\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.11932002753019333, accuracy 0.21428571428571427\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.10337016731500626, accuracy 0.22448979591836735\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 18] evaluate, config: {'server_round': 3, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-03-20 11:02:44,708 | server.py:236 | fit_round 3 received 5 results and 0 failures\n",
            "DEBUG:flwr:fit_round 3 received 5 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 141, round 3] fit, config: {'server_round': 3, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.13442963361740112, accuracy 0.07653061224489796\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.1227501705288887, accuracy 0.11734693877551021\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.11929433792829514, accuracy 0.1326530612244898\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.11342011392116547, accuracy 0.20918367346938777\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.10878249257802963, accuracy 0.1989795918367347\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 141] evaluate, config: {'server_round': 3, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "Calculating the round 2 Shapley values\n",
            "Client 18 has Shapley contribution 0.0002979654350207789\n",
            "Client 82 has Shapley contribution -4.844587407487842e-05\n",
            "Client 90 has Shapley contribution 0.0007118889535219183\n",
            "Client 141 has Shapley contribution 7.103710540312325e-05\n",
            "Client 153 has Shapley contribution -0.00011944221150999947\n",
            "Individual fairness, f_j = 0.11787373966839894\n",
            "Group fairness, f_g = 0.560000017285347\n",
            "Incentive fairness, f_r = 0.11710640817127986\n",
            "Orchestrator fairness, f_o = 0.248\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2024-03-20 11:07:19,058 | server.py:125 | fit progress: (3, 0.10189816944783231, {'accuracy': 0.24822392422076675}, 873.7307950559998)\n",
            "INFO:flwr:fit progress: (3, 0.10189816944783231, {'accuracy': 0.24822392422076675}, 873.7307950559998)\n",
            "INFO flwr 2024-03-20 11:07:19,061 | server.py:171 | evaluate_round 3: no clients selected, cancel\n",
            "INFO:flwr:evaluate_round 3: no clients selected, cancel\n",
            "DEBUG flwr 2024-03-20 11:07:19,065 | server.py:222 | fit_round 4: strategy sampled 5 clients (out of 205)\n",
            "DEBUG:flwr:fit_round 4: strategy sampled 5 clients (out of 205)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Server-side evaluation loss 0.10189816944783231 / accuracy 0.24822392422076675\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 105, round 4] fit, config: {'server_round': 4, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.12275874614715576, accuracy 0.1836734693877551\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.11236529052257538, accuracy 0.17857142857142858\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.10054934769868851, accuracy 0.2857142857142857\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.09671012312173843, accuracy 0.32653061224489793\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.08354011923074722, accuracy 0.4336734693877551\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 105] evaluate, config: {'server_round': 4, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 75, round 4] fit, config: {'server_round': 4, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.11290236562490463, accuracy 0.25510204081632654\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.10769663006067276, accuracy 0.28061224489795916\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.10000725835561752, accuracy 0.35714285714285715\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.09525589644908905, accuracy 0.3163265306122449\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.09282806515693665, accuracy 0.39285714285714285\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 75] evaluate, config: {'server_round': 4, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 154, round 4] fit, config: {'server_round': 4, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.11799383908510208, accuracy 0.24489795918367346\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.1050809919834137, accuracy 0.29081632653061223\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.09923528879880905, accuracy 0.32142857142857145\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.09324764460325241, accuracy 0.3520408163265306\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.08367560058832169, accuracy 0.44387755102040816\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 154] evaluate, config: {'server_round': 4, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 199, round 4] fit, config: {'server_round': 4, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.11969411373138428, accuracy 0.2193877551020408\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.10550617426633835, accuracy 0.28061224489795916\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.0940588116645813, accuracy 0.34183673469387754\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.08433901518583298, accuracy 0.3673469387755102\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.08229859918355942, accuracy 0.3877551020408163\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 199] evaluate, config: {'server_round': 4, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-03-20 11:07:33,438 | server.py:236 | fit_round 4 received 5 results and 0 failures\n",
            "DEBUG:flwr:fit_round 4 received 5 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 140, round 4] fit, config: {'server_round': 4, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.12240127474069595, accuracy 0.2193877551020408\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.10684221237897873, accuracy 0.28061224489795916\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.09827253222465515, accuracy 0.2755102040816326\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.09365559369325638, accuracy 0.32653061224489793\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.083944171667099, accuracy 0.3469387755102041\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 140] evaluate, config: {'server_round': 4, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "Calculating the round 3 Shapley values\n",
            "Client 75 has Shapley contribution -0.0012585359292665154\n",
            "Client 105 has Shapley contribution 0.001477951565838263\n",
            "Client 140 has Shapley contribution 0.0007493688986219874\n",
            "Client 154 has Shapley contribution 0.0009356310163294211\n",
            "Client 199 has Shapley contribution 0.0017625679573906848\n",
            "Individual fairness, f_j = 0.43974446718211796\n",
            "Group fairness, f_g = 0.6400000125169754\n",
            "Incentive fairness, f_r = 0.2049796946328666\n",
            "Orchestrator fairness, f_o = 0.336\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2024-03-20 11:12:06,846 | server.py:125 | fit progress: (4, 0.0852109406238719, {'accuracy': 0.35297506026923814}, 1161.519074161)\n",
            "INFO:flwr:fit progress: (4, 0.0852109406238719, {'accuracy': 0.35297506026923814}, 1161.519074161)\n",
            "INFO flwr 2024-03-20 11:12:06,850 | server.py:171 | evaluate_round 4: no clients selected, cancel\n",
            "INFO:flwr:evaluate_round 4: no clients selected, cancel\n",
            "DEBUG flwr 2024-03-20 11:12:06,854 | server.py:222 | fit_round 5: strategy sampled 5 clients (out of 205)\n",
            "DEBUG:flwr:fit_round 5: strategy sampled 5 clients (out of 205)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Server-side evaluation loss 0.0852109406238719 / accuracy 0.35297506026923814\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 104, round 5] fit, config: {'server_round': 5, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.09725350886583328, accuracy 0.37244897959183676\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.09354818612337112, accuracy 0.37244897959183676\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.08687186241149902, accuracy 0.45408163265306123\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.06978882104158401, accuracy 0.47959183673469385\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.06731113791465759, accuracy 0.45918367346938777\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 104] evaluate, config: {'server_round': 5, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 121, round 5] fit, config: {'server_round': 5, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.1013215109705925, accuracy 0.27040816326530615\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.08845444768667221, accuracy 0.3826530612244898\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.07547933608293533, accuracy 0.44387755102040816\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.06623029708862305, accuracy 0.5102040816326531\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.06255970150232315, accuracy 0.5306122448979592\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 121] evaluate, config: {'server_round': 5, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 169, round 5] fit, config: {'server_round': 5, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.10654592514038086, accuracy 0.30612244897959184\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.09665761142969131, accuracy 0.37755102040816324\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.08284357190132141, accuracy 0.37755102040816324\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.07129460573196411, accuracy 0.47959183673469385\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.07737420499324799, accuracy 0.4489795918367347\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 169] evaluate, config: {'server_round': 5, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 70, round 5] fit, config: {'server_round': 5, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.10192026942968369, accuracy 0.3163265306122449\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.08424192667007446, accuracy 0.33163265306122447\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.0870208591222763, accuracy 0.3826530612244898\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.0739055797457695, accuracy 0.4744897959183674\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.07114493101835251, accuracy 0.45918367346938777\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 70] evaluate, config: {'server_round': 5, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 176, round 5] fit, config: {'server_round': 5, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.10278476774692535, accuracy 0.32142857142857145\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.09346597641706467, accuracy 0.3673469387755102\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.08267365396022797, accuracy 0.37244897959183676\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-03-20 11:12:21,300 | server.py:236 | fit_round 5 received 5 results and 0 failures\n",
            "DEBUG:flwr:fit_round 5 received 5 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.07177890837192535, accuracy 0.4387755102040816\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.06789083778858185, accuracy 0.4897959183673469\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 176] evaluate, config: {'server_round': 5, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "Calculating the round 4 Shapley values\n",
            "Client 70 has Shapley contribution 0.0008112486433505236\n",
            "Client 104 has Shapley contribution 0.00037923704552161755\n",
            "Client 121 has Shapley contribution 0.00234856185649335\n",
            "Client 169 has Shapley contribution 0.002253563446394288\n",
            "Client 176 has Shapley contribution 0.0028550758069530316\n",
            "Individual fairness, f_j = 0.5659404628765677\n",
            "Group fairness, f_g = 0.8320000037550926\n",
            "Incentive fairness, f_r = 0.47279759726143344\n",
            "Orchestrator fairness, f_o = 0.42400000000000004\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2024-03-20 11:16:56,545 | server.py:125 | fit progress: (5, 0.07075520375400926, {'accuracy': 0.46704926076845943}, 1451.2180244309998)\n",
            "INFO:flwr:fit progress: (5, 0.07075520375400926, {'accuracy': 0.46704926076845943}, 1451.2180244309998)\n",
            "INFO flwr 2024-03-20 11:16:56,549 | server.py:171 | evaluate_round 5: no clients selected, cancel\n",
            "INFO:flwr:evaluate_round 5: no clients selected, cancel\n",
            "DEBUG flwr 2024-03-20 11:16:56,555 | server.py:222 | fit_round 6: strategy sampled 5 clients (out of 205)\n",
            "DEBUG:flwr:fit_round 6: strategy sampled 5 clients (out of 205)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Server-side evaluation loss 0.07075520375400926 / accuracy 0.46704926076845943\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 168, round 6] fit, config: {'server_round': 6, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.0929696261882782, accuracy 0.3979591836734694\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.08601625263690948, accuracy 0.4387755102040816\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.07010652124881744, accuracy 0.5306122448979592\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.06350730359554291, accuracy 0.5153061224489796\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.05289260670542717, accuracy 0.576530612244898\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 168] evaluate, config: {'server_round': 6, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 131, round 6] fit, config: {'server_round': 6, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.089779794216156, accuracy 0.336734693877551\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.0866495817899704, accuracy 0.4387755102040816\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.0705767497420311, accuracy 0.46938775510204084\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.06089987978339195, accuracy 0.46938775510204084\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.055196262896060944, accuracy 0.5204081632653061\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 131] evaluate, config: {'server_round': 6, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 143, round 6] fit, config: {'server_round': 6, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.09144625812768936, accuracy 0.3520408163265306\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.08310086280107498, accuracy 0.45408163265306123\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.06522511690855026, accuracy 0.5051020408163265\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.05852003023028374, accuracy 0.5561224489795918\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.0525483675301075, accuracy 0.5969387755102041\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 143] evaluate, config: {'server_round': 6, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 40, round 6] fit, config: {'server_round': 6, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.08840293437242508, accuracy 0.413265306122449\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.07771175354719162, accuracy 0.45918367346938777\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.0657707005739212, accuracy 0.5255102040816326\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.06374770402908325, accuracy 0.5306122448979592\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.05423391982913017, accuracy 0.5459183673469388\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 40] evaluate, config: {'server_round': 6, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-03-20 11:17:11,032 | server.py:236 | fit_round 6 received 5 results and 0 failures\n",
            "DEBUG:flwr:fit_round 6 received 5 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 7, round 6] fit, config: {'server_round': 6, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.0940551608800888, accuracy 0.413265306122449\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.08282551914453506, accuracy 0.4489795918367347\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.07924120128154755, accuracy 0.47959183673469385\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.05650274083018303, accuracy 0.5\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.0556907057762146, accuracy 0.5306122448979592\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 7] evaluate, config: {'server_round': 6, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "Calculating the round 5 Shapley values\n",
            "Client 7 has Shapley contribution 0.0013068303804623965\n",
            "Client 40 has Shapley contribution 0.0013970420958675897\n",
            "Client 131 has Shapley contribution 0.002362016500458671\n",
            "Client 143 has Shapley contribution 0.002277259878724519\n",
            "Client 168 has Shapley contribution 0.002776473523129822\n",
            "Individual fairness, f_j = 0.8516084974260238\n",
            "Group fairness, f_g = 0.8560000039637089\n",
            "Incentive fairness, f_r = 0.821839212128635\n",
            "Orchestrator fairness, f_o = 0.624\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2024-03-20 11:21:44,030 | server.py:125 | fit progress: (6, 0.05819377410638946, {'accuracy': 0.5456446141702046}, 1738.7028640130002)\n",
            "INFO:flwr:fit progress: (6, 0.05819377410638946, {'accuracy': 0.5456446141702046}, 1738.7028640130002)\n",
            "INFO flwr 2024-03-20 11:21:44,033 | server.py:171 | evaluate_round 6: no clients selected, cancel\n",
            "INFO:flwr:evaluate_round 6: no clients selected, cancel\n",
            "DEBUG flwr 2024-03-20 11:21:44,037 | server.py:222 | fit_round 7: strategy sampled 5 clients (out of 205)\n",
            "DEBUG:flwr:fit_round 7: strategy sampled 5 clients (out of 205)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Server-side evaluation loss 0.05819377410638946 / accuracy 0.5456446141702046\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 49, round 7] fit, config: {'server_round': 7, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.08013036102056503, accuracy 0.5408163265306123\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.05976197123527527, accuracy 0.5663265306122449\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.0478663444519043, accuracy 0.6071428571428571\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.04712327569723129, accuracy 0.673469387755102\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.03651544824242592, accuracy 0.6785714285714286\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 49] evaluate, config: {'server_round': 7, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 1, round 7] fit, config: {'server_round': 7, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.0877331793308258, accuracy 0.3877551020408163\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.07876412570476532, accuracy 0.4642857142857143\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.06250190734863281, accuracy 0.5510204081632653\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.05489921569824219, accuracy 0.5663265306122449\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.04855436459183693, accuracy 0.6122448979591837\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 1] evaluate, config: {'server_round': 7, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 70, round 7] fit, config: {'server_round': 7, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.07685275375843048, accuracy 0.45408163265306123\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.062144678086042404, accuracy 0.5714285714285714\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.04991510882973671, accuracy 0.6122448979591837\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.046771660447120667, accuracy 0.6581632653061225\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.044038280844688416, accuracy 0.7091836734693877\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 70] evaluate, config: {'server_round': 7, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 32, round 7] fit, config: {'server_round': 7, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.08517282456159592, accuracy 0.45918367346938777\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.06600148230791092, accuracy 0.5408163265306123\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.061187922954559326, accuracy 0.5408163265306123\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.047407254576683044, accuracy 0.576530612244898\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.03730621188879013, accuracy 0.6020408163265306\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 32] evaluate, config: {'server_round': 7, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-03-20 11:21:58,189 | server.py:236 | fit_round 7 received 5 results and 0 failures\n",
            "DEBUG:flwr:fit_round 7 received 5 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 137, round 7] fit, config: {'server_round': 7, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.06953980773687363, accuracy 0.45918367346938777\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.061908915638923645, accuracy 0.5051020408163265\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.051813870668411255, accuracy 0.6020408163265306\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.04384303465485573, accuracy 0.6428571428571429\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.03487834334373474, accuracy 0.6581632653061225\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 137] evaluate, config: {'server_round': 7, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "Calculating the round 6 Shapley values\n",
            "Client 1 has Shapley contribution 0.0020727192203514964\n",
            "Client 32 has Shapley contribution 0.0014281475090177028\n",
            "Client 49 has Shapley contribution 0.0022812033528214946\n",
            "Client 70 has Shapley contribution 0.0012346900264602653\n",
            "Client 137 has Shapley contribution 0.0016561669583743444\n",
            "Individual fairness, f_j = 0.12995805364329807\n",
            "Group fairness, f_g = 0.8960000030696392\n",
            "Incentive fairness, f_r = 0.12880649658176407\n",
            "Orchestrator fairness, f_o = 0.56\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2024-03-20 11:26:32,321 | server.py:125 | fit progress: (7, 0.054700535158014076, {'accuracy': 0.5746378512149851}, 2026.9942375839996)\n",
            "INFO:flwr:fit progress: (7, 0.054700535158014076, {'accuracy': 0.5746378512149851}, 2026.9942375839996)\n",
            "INFO flwr 2024-03-20 11:26:32,325 | server.py:171 | evaluate_round 7: no clients selected, cancel\n",
            "INFO:flwr:evaluate_round 7: no clients selected, cancel\n",
            "DEBUG flwr 2024-03-20 11:26:32,329 | server.py:222 | fit_round 8: strategy sampled 5 clients (out of 205)\n",
            "DEBUG:flwr:fit_round 8: strategy sampled 5 clients (out of 205)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Server-side evaluation loss 0.054700535158014076 / accuracy 0.5746378512149851\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 32, round 8] fit, config: {'server_round': 8, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.07457144558429718, accuracy 0.5153061224489796\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.05075022205710411, accuracy 0.5408163265306123\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.0553094781935215, accuracy 0.6173469387755102\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.042275864630937576, accuracy 0.6683673469387755\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.034395717084407806, accuracy 0.7295918367346939\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 32] evaluate, config: {'server_round': 8, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 190, round 8] fit, config: {'server_round': 8, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.07070394605398178, accuracy 0.5204081632653061\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.05590324476361275, accuracy 0.6479591836734694\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.04408971220254898, accuracy 0.7142857142857143\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.03867238014936447, accuracy 0.7448979591836735\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.03250555694103241, accuracy 0.75\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 190] evaluate, config: {'server_round': 8, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 109, round 8] fit, config: {'server_round': 8, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.07093972712755203, accuracy 0.5612244897959183\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.0575629323720932, accuracy 0.6224489795918368\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.03927948325872421, accuracy 0.6530612244897959\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.036290042102336884, accuracy 0.7040816326530612\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.034610070288181305, accuracy 0.7397959183673469\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 109] evaluate, config: {'server_round': 8, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 19, round 8] fit, config: {'server_round': 8, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.06945746392011642, accuracy 0.5408163265306123\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.05886887386441231, accuracy 0.5714285714285714\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.047435130923986435, accuracy 0.6071428571428571\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.04707392305135727, accuracy 0.673469387755102\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.03227989375591278, accuracy 0.6785714285714286\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 19] evaluate, config: {'server_round': 8, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-03-20 11:26:47,007 | server.py:236 | fit_round 8 received 5 results and 0 failures\n",
            "DEBUG:flwr:fit_round 8 received 5 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 1, round 8] fit, config: {'server_round': 8, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.06978816539049149, accuracy 0.4846938775510204\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.05167975649237633, accuracy 0.6173469387755102\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.04500153660774231, accuracy 0.5867346938775511\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.03632063791155815, accuracy 0.6989795918367347\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.03276108577847481, accuracy 0.673469387755102\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 1] evaluate, config: {'server_round': 8, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "Calculating the round 7 Shapley values\n",
            "Client 1 has Shapley contribution 0.001106335297163854\n",
            "Client 19 has Shapley contribution 0.0029735693338775763\n",
            "Client 32 has Shapley contribution 0.0024193833547180073\n",
            "Client 109 has Shapley contribution 0.0019244991723504964\n",
            "Client 190 has Shapley contribution 0.002940275291210582\n",
            "Individual fairness, f_j = 0.9342112648744338\n",
            "Group fairness, f_g = 0.9600000001490117\n",
            "Incentive fairness, f_r = 0.9195422209277923\n",
            "Orchestrator fairness, f_o = 0.568\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2024-03-20 11:31:19,740 | server.py:125 | fit progress: (8, 0.04880917371635493, {'accuracy': 0.6201437928018262}, 2314.4132326989998)\n",
            "INFO:flwr:fit progress: (8, 0.04880917371635493, {'accuracy': 0.6201437928018262}, 2314.4132326989998)\n",
            "INFO flwr 2024-03-20 11:31:19,744 | server.py:171 | evaluate_round 8: no clients selected, cancel\n",
            "INFO:flwr:evaluate_round 8: no clients selected, cancel\n",
            "DEBUG flwr 2024-03-20 11:31:19,747 | server.py:222 | fit_round 9: strategy sampled 5 clients (out of 205)\n",
            "DEBUG:flwr:fit_round 9: strategy sampled 5 clients (out of 205)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Server-side evaluation loss 0.04880917371635493 / accuracy 0.6201437928018262\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 132, round 9] fit, config: {'server_round': 9, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.06760330498218536, accuracy 0.5255102040816326\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.05266271159052849, accuracy 0.5867346938775511\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.03815148025751114, accuracy 0.6785714285714286\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.030428603291511536, accuracy 0.7193877551020408\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.03180193901062012, accuracy 0.7653061224489796\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 132] evaluate, config: {'server_round': 9, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 111, round 9] fit, config: {'server_round': 9, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.07030855119228363, accuracy 0.5255102040816326\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.06762430816888809, accuracy 0.5663265306122449\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.047537460923194885, accuracy 0.6122448979591837\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.048298776149749756, accuracy 0.6581632653061225\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.033868107944726944, accuracy 0.7193877551020408\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 111] evaluate, config: {'server_round': 9, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 80, round 9] fit, config: {'server_round': 9, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.05753867328166962, accuracy 0.5357142857142857\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.0521186888217926, accuracy 0.6275510204081632\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.04156109318137169, accuracy 0.6836734693877551\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.032840415835380554, accuracy 0.7091836734693877\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.03642796725034714, accuracy 0.7551020408163265\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 80] evaluate, config: {'server_round': 9, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 140, round 9] fit, config: {'server_round': 9, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.07338683307170868, accuracy 0.5408163265306123\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.06040090322494507, accuracy 0.6377551020408163\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.044608257710933685, accuracy 0.6632653061224489\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.030540907755494118, accuracy 0.7142857142857143\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.031010113656520844, accuracy 0.7806122448979592\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 140] evaluate, config: {'server_round': 9, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-03-20 11:31:33,482 | server.py:236 | fit_round 9 received 5 results and 0 failures\n",
            "DEBUG:flwr:fit_round 9 received 5 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 81, round 9] fit, config: {'server_round': 9, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.07405869662761688, accuracy 0.49489795918367346\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.05078308656811714, accuracy 0.6326530612244898\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.03787880018353462, accuracy 0.6785714285714286\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.0315750427544117, accuracy 0.7193877551020408\n",
            "Calculating the round 8 Shapley values\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.029176652431488037, accuracy 0.7959183673469388\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 81] evaluate, config: {'server_round': 9, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "Client 80 has Shapley contribution 0.0019017464300849958\n",
            "Client 81 has Shapley contribution 0.001839599381928807\n",
            "Client 111 has Shapley contribution 0.0031852712917568985\n",
            "Client 132 has Shapley contribution 0.000882509722704332\n",
            "Client 140 has Shapley contribution 0.002365855380842632\n",
            "Individual fairness, f_j = 0.7829044423911735\n",
            "Group fairness, f_g = 0.8640000052750111\n",
            "Incentive fairness, f_r = 0.8605649463875312\n",
            "Orchestrator fairness, f_o = 0.6080000000000001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2024-03-20 11:36:07,288 | server.py:125 | fit progress: (9, 0.043506447428553016, {'accuracy': 0.6475156273334329}, 2601.961014858)\n",
            "INFO:flwr:fit progress: (9, 0.043506447428553016, {'accuracy': 0.6475156273334329}, 2601.961014858)\n",
            "INFO flwr 2024-03-20 11:36:07,291 | server.py:171 | evaluate_round 9: no clients selected, cancel\n",
            "INFO:flwr:evaluate_round 9: no clients selected, cancel\n",
            "DEBUG flwr 2024-03-20 11:36:07,295 | server.py:222 | fit_round 10: strategy sampled 5 clients (out of 205)\n",
            "DEBUG:flwr:fit_round 10: strategy sampled 5 clients (out of 205)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Server-side evaluation loss 0.043506447428553016 / accuracy 0.6475156273334329\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 116, round 10] fit, config: {'server_round': 10, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.05471912398934364, accuracy 0.6122448979591837\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.042480532079935074, accuracy 0.6377551020408163\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.03391559049487114, accuracy 0.7397959183673469\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.025015641003847122, accuracy 0.7755102040816326\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.023491717875003815, accuracy 0.7806122448979592\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 116] evaluate, config: {'server_round': 10, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 117, round 10] fit, config: {'server_round': 10, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.06457541882991791, accuracy 0.5816326530612245\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.04513928294181824, accuracy 0.6428571428571429\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.03510501980781555, accuracy 0.7397959183673469\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.026347648352384567, accuracy 0.7448979591836735\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.027265895158052444, accuracy 0.8061224489795918\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 117] evaluate, config: {'server_round': 10, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 105, round 10] fit, config: {'server_round': 10, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.06074828281998634, accuracy 0.5510204081632653\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.0522611178457737, accuracy 0.6632653061224489\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.04052504152059555, accuracy 0.6785714285714286\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.04381762444972992, accuracy 0.7551020408163265\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.032135508954524994, accuracy 0.7704081632653061\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 105] evaluate, config: {'server_round': 10, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 133, round 10] fit, config: {'server_round': 10, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.07266223430633545, accuracy 0.5357142857142857\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.05083581432700157, accuracy 0.6326530612244898\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.035692013800144196, accuracy 0.6479591836734694\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.040772467851638794, accuracy 0.6887755102040817\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.029687240719795227, accuracy 0.7704081632653061\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 133] evaluate, config: {'server_round': 10, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-03-20 11:36:21,661 | server.py:236 | fit_round 10 received 5 results and 0 failures\n",
            "DEBUG:flwr:fit_round 10 received 5 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 109, round 10] fit, config: {'server_round': 10, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.044583212584257126, accuracy 0.6632653061224489\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.03705188259482384, accuracy 0.7295918367346939\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.03016197867691517, accuracy 0.75\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.022553524002432823, accuracy 0.8112244897959183\n",
            "Calculating the round 9 Shapley values\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.016898155212402344, accuracy 0.8622448979591837\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 109] evaluate, config: {'server_round': 10, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "Client 105 has Shapley contribution 0.002833381483923169\n",
            "Client 109 has Shapley contribution 0.001252653787161069\n",
            "Client 116 has Shapley contribution 0.0027065292750496537\n",
            "Client 117 has Shapley contribution 0.0015992031148620253\n",
            "Client 133 has Shapley contribution 0.003111918313113015\n",
            "Individual fairness, f_j = 0.8717665710944317\n",
            "Group fairness, f_g = 0.8080000065267086\n",
            "Incentive fairness, f_r = 0.8331769808727318\n",
            "Orchestrator fairness, f_o = 0.624\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2024-03-20 11:40:54,548 | server.py:125 | fit progress: (10, 0.04056903966977807, {'accuracy': 0.6650523755680242}, 2889.221000809)\n",
            "INFO:flwr:fit progress: (10, 0.04056903966977807, {'accuracy': 0.6650523755680242}, 2889.221000809)\n",
            "INFO flwr 2024-03-20 11:40:54,552 | server.py:171 | evaluate_round 10: no clients selected, cancel\n",
            "INFO:flwr:evaluate_round 10: no clients selected, cancel\n",
            "DEBUG flwr 2024-03-20 11:40:54,556 | server.py:222 | fit_round 11: strategy sampled 5 clients (out of 205)\n",
            "DEBUG:flwr:fit_round 11: strategy sampled 5 clients (out of 205)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Server-side evaluation loss 0.04056903966977807 / accuracy 0.6650523755680242\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 29, round 11] fit, config: {'server_round': 11, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.06010971963405609, accuracy 0.5867346938775511\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.039357464760541916, accuracy 0.6377551020408163\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.030040504410862923, accuracy 0.6989795918367347\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.03053894266486168, accuracy 0.7908163265306123\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.02200821414589882, accuracy 0.8214285714285714\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 29] evaluate, config: {'server_round': 11, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 102, round 11] fit, config: {'server_round': 11, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.06069367751479149, accuracy 0.5408163265306123\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.040630657225847244, accuracy 0.6377551020408163\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.036577772349119186, accuracy 0.7295918367346939\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.028864499181509018, accuracy 0.75\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.02212323620915413, accuracy 0.8010204081632653\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 102] evaluate, config: {'server_round': 11, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 145, round 11] fit, config: {'server_round': 11, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.05311616137623787, accuracy 0.6020408163265306\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.05183316022157669, accuracy 0.7091836734693877\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.030635597184300423, accuracy 0.7806122448979592\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.02448439970612526, accuracy 0.8112244897959183\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.018999401479959488, accuracy 0.8112244897959183\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 145] evaluate, config: {'server_round': 11, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 25, round 11] fit, config: {'server_round': 11, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.056468136608600616, accuracy 0.5816326530612245\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.03988417610526085, accuracy 0.6785714285714286\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.030542373657226562, accuracy 0.7448979591836735\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.024270925670862198, accuracy 0.8163265306122449\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.019329147413372993, accuracy 0.7908163265306123\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 25] evaluate, config: {'server_round': 11, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-03-20 11:41:08,332 | server.py:236 | fit_round 11 received 5 results and 0 failures\n",
            "DEBUG:flwr:fit_round 11 received 5 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 174, round 11] fit, config: {'server_round': 11, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.059133030474185944, accuracy 0.5663265306122449\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.04577891528606415, accuracy 0.6377551020408163\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.037904396653175354, accuracy 0.7551020408163265\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.029669228941202164, accuracy 0.6989795918367347\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.022527290508151054, accuracy 0.7908163265306123\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 174] evaluate, config: {'server_round': 11, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "Calculating the round 10 Shapley values\n",
            "Client 25 has Shapley contribution 0.0021999260939859063\n",
            "Client 29 has Shapley contribution 0.0028291935199291395\n",
            "Client 102 has Shapley contribution 0.0020889253352734654\n",
            "Client 145 has Shapley contribution 0.0015273722053508391\n",
            "Client 174 has Shapley contribution 0.0018864953811615647\n",
            "Individual fairness, f_j = 0.9534105822789635\n",
            "Group fairness, f_g = 0.9120000012218952\n",
            "Incentive fairness, f_r = 0.9658721732257778\n",
            "Orchestrator fairness, f_o = 0.592\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2024-03-20 11:45:49,953 | server.py:125 | fit progress: (11, 0.0388432933192499, {'accuracy': 0.6783222750837369}, 3184.625729352)\n",
            "INFO:flwr:fit progress: (11, 0.0388432933192499, {'accuracy': 0.6783222750837369}, 3184.625729352)\n",
            "INFO flwr 2024-03-20 11:45:49,959 | server.py:171 | evaluate_round 11: no clients selected, cancel\n",
            "INFO:flwr:evaluate_round 11: no clients selected, cancel\n",
            "DEBUG flwr 2024-03-20 11:45:49,963 | server.py:222 | fit_round 12: strategy sampled 5 clients (out of 205)\n",
            "DEBUG:flwr:fit_round 12: strategy sampled 5 clients (out of 205)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Server-side evaluation loss 0.0388432933192499 / accuracy 0.6783222750837369\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 189, round 12] fit, config: {'server_round': 12, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.057082757353782654, accuracy 0.6224489795918368\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.03870195522904396, accuracy 0.6581632653061225\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.032774344086647034, accuracy 0.7755102040816326\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.023181235417723656, accuracy 0.8163265306122449\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.020581478253006935, accuracy 0.8112244897959183\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 189] evaluate, config: {'server_round': 12, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 26, round 12] fit, config: {'server_round': 12, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.04752923548221588, accuracy 0.6479591836734694\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.03415783494710922, accuracy 0.6836734693877551\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.02901313453912735, accuracy 0.7806122448979592\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.019814452156424522, accuracy 0.8061224489795918\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.021321522071957588, accuracy 0.8367346938775511\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 26] evaluate, config: {'server_round': 12, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 135, round 12] fit, config: {'server_round': 12, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.06260884553194046, accuracy 0.5714285714285714\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.0433756560087204, accuracy 0.6836734693877551\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.032633207738399506, accuracy 0.6632653061224489\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.03222445026040077, accuracy 0.7397959183673469\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.021588675677776337, accuracy 0.7857142857142857\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 135] evaluate, config: {'server_round': 12, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 62, round 12] fit, config: {'server_round': 12, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.0594317652285099, accuracy 0.6224489795918368\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.03928971290588379, accuracy 0.7346938775510204\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.03313017264008522, accuracy 0.7551020408163265\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.030087482184171677, accuracy 0.7908163265306123\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.02246999181807041, accuracy 0.7908163265306123\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 62] evaluate, config: {'server_round': 12, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 83, round 12] fit, config: {'server_round': 12, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.05534878373146057, accuracy 0.5969387755102041\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.03874202445149422, accuracy 0.7448979591836735\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.033105529844760895, accuracy 0.7653061224489796\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.02685503289103508, accuracy 0.8061224489795918\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.018340539187192917, accuracy 0.8520408163265306\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 83] evaluate, config: {'server_round': 12, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-03-20 11:46:13,389 | server.py:236 | fit_round 12 received 5 results and 0 failures\n",
            "DEBUG:flwr:fit_round 12 received 5 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating the round 11 Shapley values\n",
            "Client 26 has Shapley contribution 0.0014176050115661154\n",
            "Client 62 has Shapley contribution 0.0027652672024349283\n",
            "Client 83 has Shapley contribution 0.0013665537218737296\n",
            "Client 135 has Shapley contribution 0.002596006613946363\n",
            "Client 189 has Shapley contribution 0.0022415306484278178\n",
            "Individual fairness, f_j = 0.9573816327224879\n",
            "Group fairness, f_g = 0.9120000027120113\n",
            "Incentive fairness, f_r = 0.9206740029956576\n",
            "Orchestrator fairness, f_o = 0.4880000000000001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2024-03-20 11:51:17,280 | server.py:125 | fit progress: (12, 0.03668699396609538, {'accuracy': 0.6903761227145692}, 3511.952779326)\n",
            "INFO:flwr:fit progress: (12, 0.03668699396609538, {'accuracy': 0.6903761227145692}, 3511.952779326)\n",
            "INFO flwr 2024-03-20 11:51:17,284 | server.py:171 | evaluate_round 12: no clients selected, cancel\n",
            "INFO:flwr:evaluate_round 12: no clients selected, cancel\n",
            "DEBUG flwr 2024-03-20 11:51:17,288 | server.py:222 | fit_round 13: strategy sampled 5 clients (out of 205)\n",
            "DEBUG:flwr:fit_round 13: strategy sampled 5 clients (out of 205)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Server-side evaluation loss 0.03668699396609538 / accuracy 0.6903761227145692\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 185, round 13] fit, config: {'server_round': 13, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.05249449238181114, accuracy 0.6173469387755102\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.03516600281000137, accuracy 0.6887755102040817\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.027118278667330742, accuracy 0.7244897959183674\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.02718268148601055, accuracy 0.7806122448979592\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.020993497222661972, accuracy 0.7908163265306123\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 185] evaluate, config: {'server_round': 13, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 119, round 13] fit, config: {'server_round': 13, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.047440655529499054, accuracy 0.6428571428571429\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.03608701750636101, accuracy 0.7193877551020408\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.024646949023008347, accuracy 0.7857142857142857\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.02064763940870762, accuracy 0.8571428571428571\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.02225935459136963, accuracy 0.8826530612244898\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 119] evaluate, config: {'server_round': 13, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 172, round 13] fit, config: {'server_round': 13, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.04831838607788086, accuracy 0.6020408163265306\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.03225858509540558, accuracy 0.7448979591836735\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.027562014758586884, accuracy 0.7653061224489796\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.023325499147176743, accuracy 0.8418367346938775\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.02436220832169056, accuracy 0.8163265306122449\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 172] evaluate, config: {'server_round': 13, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 12, round 13] fit, config: {'server_round': 13, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.04339299350976944, accuracy 0.6326530612244898\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.03522765263915062, accuracy 0.7397959183673469\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.02821204625070095, accuracy 0.8061224489795918\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.022760672494769096, accuracy 0.8316326530612245\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.02035623788833618, accuracy 0.8724489795918368\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 12] evaluate, config: {'server_round': 13, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-03-20 11:51:31,515 | server.py:236 | fit_round 13 received 5 results and 0 failures\n",
            "DEBUG:flwr:fit_round 13 received 5 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 55, round 13] fit, config: {'server_round': 13, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.04489205405116081, accuracy 0.6632653061224489\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.030436916276812553, accuracy 0.7244897959183674\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.024425700306892395, accuracy 0.826530612244898\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.020700883120298386, accuracy 0.826530612244898\n",
            "Calculating the round 12 Shapley values\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.017322158440947533, accuracy 0.8571428571428571\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 55] evaluate, config: {'server_round': 13, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "Client 12 has Shapley contribution 0.0019506606490157685\n",
            "Client 55 has Shapley contribution 0.001758322634856694\n",
            "Client 119 has Shapley contribution 0.002643093229940695\n",
            "Client 172 has Shapley contribution 0.0016645169922263618\n",
            "Client 185 has Shapley contribution 0.0022603880940398253\n",
            "Individual fairness, f_j = 0.961276683706735\n",
            "Group fairness, f_g = 0.7200000070035457\n",
            "Incentive fairness, f_r = 0.9677217988507221\n",
            "Orchestrator fairness, f_o = 0.6880000000000001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2024-03-20 11:56:11,140 | server.py:125 | fit progress: (13, 0.035100623289079425, {'accuracy': 0.7060567917564483}, 3805.8134039459997)\n",
            "INFO:flwr:fit progress: (13, 0.035100623289079425, {'accuracy': 0.7060567917564483}, 3805.8134039459997)\n",
            "INFO flwr 2024-03-20 11:56:11,147 | server.py:171 | evaluate_round 13: no clients selected, cancel\n",
            "INFO:flwr:evaluate_round 13: no clients selected, cancel\n",
            "DEBUG flwr 2024-03-20 11:56:11,152 | server.py:222 | fit_round 14: strategy sampled 5 clients (out of 205)\n",
            "DEBUG:flwr:fit_round 14: strategy sampled 5 clients (out of 205)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Server-side evaluation loss 0.035100623289079425 / accuracy 0.7060567917564483\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 164, round 14] fit, config: {'server_round': 14, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.0546783022582531, accuracy 0.6530612244897959\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.03764524310827255, accuracy 0.7602040816326531\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.023806797340512276, accuracy 0.7857142857142857\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.022543294355273247, accuracy 0.8418367346938775\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.016681699082255363, accuracy 0.8673469387755102\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 164] evaluate, config: {'server_round': 14, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 60, round 14] fit, config: {'server_round': 14, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.04265855252742767, accuracy 0.6224489795918368\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.030459104105830193, accuracy 0.7346938775510204\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.02346646785736084, accuracy 0.826530612244898\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.01864878088235855, accuracy 0.8571428571428571\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.016889970749616623, accuracy 0.8520408163265306\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 60] evaluate, config: {'server_round': 14, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 128, round 14] fit, config: {'server_round': 14, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.04377269744873047, accuracy 0.6938775510204082\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.028865722939372063, accuracy 0.7908163265306123\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.02496284805238247, accuracy 0.7959183673469388\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.01782742142677307, accuracy 0.8367346938775511\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.014936369843780994, accuracy 0.8367346938775511\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 128] evaluate, config: {'server_round': 14, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 24, round 14] fit, config: {'server_round': 14, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.054261714220047, accuracy 0.5663265306122449\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.041335150599479675, accuracy 0.673469387755102\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.03266388177871704, accuracy 0.7244897959183674\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.03681137040257454, accuracy 0.75\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.027630912140011787, accuracy 0.8469387755102041\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 24] evaluate, config: {'server_round': 14, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-03-20 11:56:25,569 | server.py:236 | fit_round 14 received 5 results and 0 failures\n",
            "DEBUG:flwr:fit_round 14 received 5 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 159, round 14] fit, config: {'server_round': 14, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.044737424701452255, accuracy 0.6530612244897959\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.035391513258218765, accuracy 0.7244897959183674\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.02820989303290844, accuracy 0.8163265306122449\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.021045265719294548, accuracy 0.8418367346938775\n",
            "Calculating the round 13 Shapley values\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.017230359837412834, accuracy 0.8571428571428571\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 159] evaluate, config: {'server_round': 14, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "Client 24 has Shapley contribution 0.0025986448044251964\n",
            "Client 60 has Shapley contribution 0.0017250587433068586\n",
            "Client 128 has Shapley contribution 0.0023039879119945805\n",
            "Client 159 has Shapley contribution 0.0014381273489269724\n",
            "Client 164 has Shapley contribution 0.001427365435127384\n",
            "Individual fairness, f_j = 0.9495832810410197\n",
            "Group fairness, f_g = 0.7040000051259995\n",
            "Incentive fairness, f_r = 0.9490532070326061\n",
            "Orchestrator fairness, f_o = 0.688\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2024-03-20 12:01:10,208 | server.py:125 | fit progress: (14, 0.03447514242467522, {'accuracy': 0.711411686898641}, 4104.880902430001)\n",
            "INFO:flwr:fit progress: (14, 0.03447514242467522, {'accuracy': 0.711411686898641}, 4104.880902430001)\n",
            "INFO flwr 2024-03-20 12:01:10,211 | server.py:171 | evaluate_round 14: no clients selected, cancel\n",
            "INFO:flwr:evaluate_round 14: no clients selected, cancel\n",
            "DEBUG flwr 2024-03-20 12:01:10,214 | server.py:222 | fit_round 15: strategy sampled 5 clients (out of 205)\n",
            "DEBUG:flwr:fit_round 15: strategy sampled 5 clients (out of 205)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Server-side evaluation loss 0.03447514242467522 / accuracy 0.711411686898641\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 190, round 15] fit, config: {'server_round': 15, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.05271096155047417, accuracy 0.6530612244897959\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.03282470628619194, accuracy 0.7397959183673469\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.026899507269263268, accuracy 0.7806122448979592\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.025897538289427757, accuracy 0.8367346938775511\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.018623780459165573, accuracy 0.8418367346938775\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 190] evaluate, config: {'server_round': 15, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 91, round 15] fit, config: {'server_round': 15, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.04034325107932091, accuracy 0.6479591836734694\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.045843176543712616, accuracy 0.7295918367346939\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.02295614778995514, accuracy 0.7397959183673469\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.021683715283870697, accuracy 0.8214285714285714\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.01816529594361782, accuracy 0.8367346938775511\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 91] evaluate, config: {'server_round': 15, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 80, round 15] fit, config: {'server_round': 15, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.04391038417816162, accuracy 0.6836734693877551\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.028976794332265854, accuracy 0.7346938775510204\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.022923775017261505, accuracy 0.7959183673469388\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.019914641976356506, accuracy 0.8316326530612245\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.015358910895884037, accuracy 0.8163265306122449\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 80] evaluate, config: {'server_round': 15, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 98, round 15] fit, config: {'server_round': 15, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.05298369750380516, accuracy 0.6428571428571429\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.0378405936062336, accuracy 0.7091836734693877\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.029512710869312286, accuracy 0.7857142857142857\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.021852979436516762, accuracy 0.7755102040816326\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.015728456899523735, accuracy 0.8418367346938775\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 98] evaluate, config: {'server_round': 15, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-03-20 12:01:24,936 | server.py:236 | fit_round 15 received 5 results and 0 failures\n",
            "DEBUG:flwr:fit_round 15 received 5 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 9, round 15] fit, config: {'server_round': 15, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.04369088634848595, accuracy 0.6581632653061225\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.03309599310159683, accuracy 0.7091836734693877\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.022717704996466637, accuracy 0.8010204081632653\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.021469729021191597, accuracy 0.8112244897959183\n",
            "Calculating the round 14 Shapley values\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.015809936448931694, accuracy 0.8673469387755102\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 9] evaluate, config: {'server_round': 15, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "Client 9 has Shapley contribution 0.0018181023917322025\n",
            "Client 80 has Shapley contribution 0.001136171304574898\n",
            "Client 91 has Shapley contribution 0.002624527408707683\n",
            "Client 98 has Shapley contribution 0.002172040903280628\n",
            "Client 190 has Shapley contribution 0.00218202290716925\n",
            "Individual fairness, f_j = 0.8644995495620715\n",
            "Group fairness, f_g = 0.5600000143051147\n",
            "Incentive fairness, f_r = 0.8700301511141978\n",
            "Orchestrator fairness, f_o = 0.744\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2024-03-20 12:06:06,281 | server.py:125 | fit progress: (15, 0.0331225147897977, {'accuracy': 0.7252789452349967}, 4400.954349285001)\n",
            "INFO:flwr:fit progress: (15, 0.0331225147897977, {'accuracy': 0.7252789452349967}, 4400.954349285001)\n",
            "INFO flwr 2024-03-20 12:06:06,286 | server.py:171 | evaluate_round 15: no clients selected, cancel\n",
            "INFO:flwr:evaluate_round 15: no clients selected, cancel\n",
            "DEBUG flwr 2024-03-20 12:06:06,290 | server.py:222 | fit_round 16: strategy sampled 5 clients (out of 205)\n",
            "DEBUG:flwr:fit_round 16: strategy sampled 5 clients (out of 205)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Server-side evaluation loss 0.0331225147897977 / accuracy 0.7252789452349967\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 181, round 16] fit, config: {'server_round': 16, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.0532061792910099, accuracy 0.6683673469387755\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.034494493156671524, accuracy 0.6989795918367347\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.025931870564818382, accuracy 0.75\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.01977541483938694, accuracy 0.8061224489795918\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.016212424263358116, accuracy 0.8571428571428571\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 181] evaluate, config: {'server_round': 16, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 154, round 16] fit, config: {'server_round': 16, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.045347657054662704, accuracy 0.673469387755102\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.03205574303865433, accuracy 0.7091836734693877\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.026727288961410522, accuracy 0.7959183673469388\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.025836016982793808, accuracy 0.8418367346938775\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.01583292707800865, accuracy 0.8469387755102041\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 154] evaluate, config: {'server_round': 16, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 130, round 16] fit, config: {'server_round': 16, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.04378071427345276, accuracy 0.6530612244897959\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.029062893241643906, accuracy 0.7704081632653061\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.021660780534148216, accuracy 0.7959183673469388\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.022002166137099266, accuracy 0.8214285714285714\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.017207758501172066, accuracy 0.8469387755102041\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 130] evaluate, config: {'server_round': 16, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 87, round 16] fit, config: {'server_round': 16, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.04690922424197197, accuracy 0.673469387755102\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.026502227410674095, accuracy 0.75\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.018606387078762054, accuracy 0.7908163265306123\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.01924893818795681, accuracy 0.8571428571428571\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.018007757142186165, accuracy 0.8724489795918368\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 87] evaluate, config: {'server_round': 16, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-03-20 12:06:20,301 | server.py:236 | fit_round 16 received 5 results and 0 failures\n",
            "DEBUG:flwr:fit_round 16 received 5 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 22, round 16] fit, config: {'server_round': 16, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.05332495644688606, accuracy 0.6275510204081632\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.03375156968832016, accuracy 0.7040816326530612\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.022934231907129288, accuracy 0.75\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.02084117941558361, accuracy 0.826530612244898\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.016742484644055367, accuracy 0.8214285714285714\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 22] evaluate, config: {'server_round': 16, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "Calculating the round 15 Shapley values\n",
            "Client 22 has Shapley contribution 0.002547353693037591\n",
            "Client 87 has Shapley contribution 0.0011821733978518048\n",
            "Client 130 has Shapley contribution 0.0021915278894458884\n",
            "Client 154 has Shapley contribution 0.0024735711445116665\n",
            "Client 181 has Shapley contribution 0.0021135360997030514\n",
            "Individual fairness, f_j = 0.8716110136822411\n",
            "Group fairness, f_g = 0.6880000121891499\n",
            "Incentive fairness, f_r = 0.8859122512855468\n",
            "Orchestrator fairness, f_o = 0.6880000000000001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2024-03-20 12:10:56,990 | server.py:125 | fit progress: (16, 0.032545702634577366, {'accuracy': 0.7368847737503467}, 4691.662838976001)\n",
            "INFO:flwr:fit progress: (16, 0.032545702634577366, {'accuracy': 0.7368847737503467}, 4691.662838976001)\n",
            "INFO flwr 2024-03-20 12:10:56,994 | server.py:171 | evaluate_round 16: no clients selected, cancel\n",
            "INFO:flwr:evaluate_round 16: no clients selected, cancel\n",
            "DEBUG flwr 2024-03-20 12:10:56,998 | server.py:222 | fit_round 17: strategy sampled 5 clients (out of 205)\n",
            "DEBUG:flwr:fit_round 17: strategy sampled 5 clients (out of 205)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Server-side evaluation loss 0.032545702634577366 / accuracy 0.7368847737503467\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 138, round 17] fit, config: {'server_round': 17, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.04211026802659035, accuracy 0.6683673469387755\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.02902345173060894, accuracy 0.7704081632653061\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.019436655566096306, accuracy 0.8316326530612245\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.019554976373910904, accuracy 0.8571428571428571\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.012813461944460869, accuracy 0.8622448979591837\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 138] evaluate, config: {'server_round': 17, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 148, round 17] fit, config: {'server_round': 17, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.04641062766313553, accuracy 0.6479591836734694\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.03098556399345398, accuracy 0.7448979591836735\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.02153646945953369, accuracy 0.7857142857142857\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.018490977585315704, accuracy 0.8010204081632653\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.017015744000673294, accuracy 0.8622448979591837\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 148] evaluate, config: {'server_round': 17, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 59, round 17] fit, config: {'server_round': 17, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.043325334787368774, accuracy 0.6377551020408163\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.031030580401420593, accuracy 0.7295918367346939\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.022336550056934357, accuracy 0.7857142857142857\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.021674485877156258, accuracy 0.8112244897959183\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.015453523024916649, accuracy 0.8775510204081632\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 59] evaluate, config: {'server_round': 17, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 43, round 17] fit, config: {'server_round': 17, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.05150848254561424, accuracy 0.6479591836734694\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.04293263703584671, accuracy 0.6581632653061225\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.029128547757864, accuracy 0.7704081632653061\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.021012378856539726, accuracy 0.8061224489795918\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.017702020704746246, accuracy 0.8163265306122449\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 43] evaluate, config: {'server_round': 17, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-03-20 12:11:11,252 | server.py:236 | fit_round 17 received 5 results and 0 failures\n",
            "DEBUG:flwr:fit_round 17 received 5 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 189, round 17] fit, config: {'server_round': 17, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.044446349143981934, accuracy 0.6785714285714286\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.03514547273516655, accuracy 0.7448979591836735\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.022439105436205864, accuracy 0.7857142857142857\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.01735263504087925, accuracy 0.8214285714285714\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.016012568026781082, accuracy 0.8520408163265306\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 189] evaluate, config: {'server_round': 17, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "Calculating the round 16 Shapley values\n",
            "Client 43 has Shapley contribution 0.002791671531759997\n",
            "Client 59 has Shapley contribution 0.0018332179618092946\n",
            "Client 138 has Shapley contribution 0.0015584173393253411\n",
            "Client 148 has Shapley contribution 0.0016423187529855346\n",
            "Client 189 has Shapley contribution 0.002150738075757997\n",
            "Individual fairness, f_j = 0.8239823707716293\n",
            "Group fairness, f_g = 0.8720000073313713\n",
            "Incentive fairness, f_r = 0.8296701637833819\n",
            "Orchestrator fairness, f_o = 0.672\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2024-03-20 12:15:48,191 | server.py:125 | fit progress: (17, 0.03124842846014388, {'accuracy': 0.7350926972884176}, 4982.864124119)\n",
            "INFO:flwr:fit progress: (17, 0.03124842846014388, {'accuracy': 0.7350926972884176}, 4982.864124119)\n",
            "INFO flwr 2024-03-20 12:15:48,195 | server.py:171 | evaluate_round 17: no clients selected, cancel\n",
            "INFO:flwr:evaluate_round 17: no clients selected, cancel\n",
            "DEBUG flwr 2024-03-20 12:15:48,201 | server.py:222 | fit_round 18: strategy sampled 5 clients (out of 205)\n",
            "DEBUG:flwr:fit_round 18: strategy sampled 5 clients (out of 205)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Server-side evaluation loss 0.03124842846014388 / accuracy 0.7350926972884176\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 22, round 18] fit, config: {'server_round': 18, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.03776434063911438, accuracy 0.6938775510204082\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.023640451952815056, accuracy 0.7755102040816326\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.02176460064947605, accuracy 0.8061224489795918\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.016998998820781708, accuracy 0.8775510204081632\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.01288850512355566, accuracy 0.8418367346938775\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 22] evaluate, config: {'server_round': 18, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 36, round 18] fit, config: {'server_round': 18, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.045556019991636276, accuracy 0.6326530612244898\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.043945491313934326, accuracy 0.6887755102040817\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.03313704952597618, accuracy 0.7397959183673469\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.02552727237343788, accuracy 0.7704081632653061\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.01880190148949623, accuracy 0.8214285714285714\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 36] evaluate, config: {'server_round': 18, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 147, round 18] fit, config: {'server_round': 18, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.043240759521722794, accuracy 0.6428571428571429\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.02752896212041378, accuracy 0.75\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.023056384176015854, accuracy 0.8112244897959183\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.017994390800595284, accuracy 0.8724489795918368\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.013624108396470547, accuracy 0.8877551020408163\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 147] evaluate, config: {'server_round': 18, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 16, round 18] fit, config: {'server_round': 18, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.05724291130900383, accuracy 0.6632653061224489\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.04048552364110947, accuracy 0.7602040816326531\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.03009275160729885, accuracy 0.75\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.022789739072322845, accuracy 0.826530612244898\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.01620936580002308, accuracy 0.8571428571428571\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 16] evaluate, config: {'server_round': 18, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-03-20 12:16:02,422 | server.py:236 | fit_round 18 received 5 results and 0 failures\n",
            "DEBUG:flwr:fit_round 18 received 5 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 161, round 18] fit, config: {'server_round': 18, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.04875148832798004, accuracy 0.6785714285714286\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.03713279962539673, accuracy 0.7346938775510204\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.02705594152212143, accuracy 0.7806122448979592\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.019717687740921974, accuracy 0.8214285714285714\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.01641412451863289, accuracy 0.8775510204081632\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 161] evaluate, config: {'server_round': 18, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "Calculating the round 17 Shapley values\n",
            "Client 16 has Shapley contribution 0.003202178391909624\n",
            "Client 22 has Shapley contribution 0.001073395072597257\n",
            "Client 36 has Shapley contribution 0.0026878893907781643\n",
            "Client 147 has Shapley contribution 0.001371608948157647\n",
            "Client 161 has Shapley contribution 0.002052901503989646\n",
            "Individual fairness, f_j = 0.9107058682302024\n",
            "Group fairness, f_g = 0.7120000034570694\n",
            "Incentive fairness, f_r = 0.9074961646730932\n",
            "Orchestrator fairness, f_o = 0.64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2024-03-20 12:20:37,645 | server.py:125 | fit progress: (18, 0.0296954416426688, {'accuracy': 0.7428796962003712}, 5272.317760931999)\n",
            "INFO:flwr:fit progress: (18, 0.0296954416426688, {'accuracy': 0.7428796962003712}, 5272.317760931999)\n",
            "INFO flwr 2024-03-20 12:20:37,649 | server.py:171 | evaluate_round 18: no clients selected, cancel\n",
            "INFO:flwr:evaluate_round 18: no clients selected, cancel\n",
            "DEBUG flwr 2024-03-20 12:20:37,653 | server.py:222 | fit_round 19: strategy sampled 5 clients (out of 205)\n",
            "DEBUG:flwr:fit_round 19: strategy sampled 5 clients (out of 205)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Server-side evaluation loss 0.0296954416426688 / accuracy 0.7428796962003712\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 178, round 19] fit, config: {'server_round': 19, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.051204223185777664, accuracy 0.6428571428571429\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.037906352430582047, accuracy 0.7346938775510204\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.030704239383339882, accuracy 0.8010204081632653\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.024291805922985077, accuracy 0.8010204081632653\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.01803683489561081, accuracy 0.8520408163265306\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 178] evaluate, config: {'server_round': 19, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 202, round 19] fit, config: {'server_round': 19, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.038137368857860565, accuracy 0.6836734693877551\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.03209632635116577, accuracy 0.8061224489795918\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.02037176676094532, accuracy 0.8316326530612245\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.013998464681208134, accuracy 0.8571428571428571\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.014891848899424076, accuracy 0.8622448979591837\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 202] evaluate, config: {'server_round': 19, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 111, round 19] fit, config: {'server_round': 19, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.0428718626499176, accuracy 0.6581632653061225\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.035612866282463074, accuracy 0.7448979591836735\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.029109731316566467, accuracy 0.8112244897959183\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.021424857899546623, accuracy 0.8112244897959183\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.015407940372824669, accuracy 0.8469387755102041\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 111] evaluate, config: {'server_round': 19, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 125, round 19] fit, config: {'server_round': 19, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.04475431516766548, accuracy 0.6632653061224489\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.027063541114330292, accuracy 0.7908163265306123\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.020889315754175186, accuracy 0.8316326530612245\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.016632989048957825, accuracy 0.826530612244898\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.014852923341095448, accuracy 0.8826530612244898\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 125] evaluate, config: {'server_round': 19, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-03-20 12:20:52,022 | server.py:236 | fit_round 19 received 5 results and 0 failures\n",
            "DEBUG:flwr:fit_round 19 received 5 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 128, round 19] fit, config: {'server_round': 19, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.03177708014845848, accuracy 0.7857142857142857\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.020390359684824944, accuracy 0.7959183673469388\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.016329286620020866, accuracy 0.8316326530612245\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.01710103638470173, accuracy 0.8979591836734694\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.011622346006333828, accuracy 0.9132653061224489\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 128] evaluate, config: {'server_round': 19, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "Calculating the round 18 Shapley values\n",
            "Client 111 has Shapley contribution 0.0020303291264626546\n",
            "Client 125 has Shapley contribution 0.0016191129249439752\n",
            "Client 128 has Shapley contribution 0.001454972287593866\n",
            "Client 178 has Shapley contribution 0.0020024972338662855\n",
            "Client 202 has Shapley contribution 0.0012843004000817732\n",
            "Individual fairness, f_j = 0.8494745850768001\n",
            "Group fairness, f_g = 0.5680000126361847\n",
            "Incentive fairness, f_r = 0.7799238107677074\n",
            "Orchestrator fairness, f_o = 0.768\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2024-03-20 12:25:34,599 | server.py:125 | fit progress: (19, 0.02995062164064687, {'accuracy': 0.7450557890469993}, 5569.272290041999)\n",
            "INFO:flwr:fit progress: (19, 0.02995062164064687, {'accuracy': 0.7450557890469993}, 5569.272290041999)\n",
            "INFO flwr 2024-03-20 12:25:34,607 | server.py:171 | evaluate_round 19: no clients selected, cancel\n",
            "INFO:flwr:evaluate_round 19: no clients selected, cancel\n",
            "DEBUG flwr 2024-03-20 12:25:34,612 | server.py:222 | fit_round 20: strategy sampled 5 clients (out of 205)\n",
            "DEBUG:flwr:fit_round 20: strategy sampled 5 clients (out of 205)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Server-side evaluation loss 0.02995062164064687 / accuracy 0.7450557890469993\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 4, round 20] fit, config: {'server_round': 20, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.049059219658374786, accuracy 0.7142857142857143\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.02754855901002884, accuracy 0.7857142857142857\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.021731123328208923, accuracy 0.7806122448979592\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.017976311966776848, accuracy 0.8469387755102041\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.013079939410090446, accuracy 0.8418367346938775\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 4] evaluate, config: {'server_round': 20, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 176, round 20] fit, config: {'server_round': 20, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.043848950415849686, accuracy 0.6989795918367347\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.029868798330426216, accuracy 0.8214285714285714\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.022626163437962532, accuracy 0.8418367346938775\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.016681699082255363, accuracy 0.8520408163265306\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.013871563598513603, accuracy 0.8622448979591837\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 176] evaluate, config: {'server_round': 20, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 112, round 20] fit, config: {'server_round': 20, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.036409638822078705, accuracy 0.7397959183673469\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.023137696087360382, accuracy 0.8622448979591837\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.020335031673312187, accuracy 0.8622448979591837\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.01311696507036686, accuracy 0.8826530612244898\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.01586175337433815, accuracy 0.9081632653061225\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 112] evaluate, config: {'server_round': 20, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 54, round 20] fit, config: {'server_round': 20, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.04194696992635727, accuracy 0.7091836734693877\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.03372752666473389, accuracy 0.8061224489795918\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.021437155082821846, accuracy 0.8622448979591837\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.016489170491695404, accuracy 0.8367346938775511\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.012031816877424717, accuracy 0.8724489795918368\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 54] evaluate, config: {'server_round': 20, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-03-20 12:25:48,981 | server.py:236 | fit_round 20 received 5 results and 0 failures\n",
            "DEBUG:flwr:fit_round 20 received 5 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 50, round 20] fit, config: {'server_round': 20, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 1: train loss 0.03611742705106735, accuracy 0.7040816326530612\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 2: train loss 0.02962704934179783, accuracy 0.7653061224489796\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 3: train loss 0.020048851147294044, accuracy 0.826530612244898\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 4: train loss 0.017984537407755852, accuracy 0.8775510204081632\n",
            "Calculating the round 19 Shapley values\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m Epoch 5: train loss 0.0118995551019907, accuracy 0.9132653061224489\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m [Client 50] evaluate, config: {'server_round': 20, 'local_epochs': 5, 'sensitive_attributes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
            "Client 4 has Shapley contribution 0.002148629615710153\n",
            "Client 50 has Shapley contribution 0.0019857436125636846\n",
            "Client 54 has Shapley contribution 0.0012243616894438663\n",
            "Client 112 has Shapley contribution 0.0022836981657280092\n",
            "Client 176 has Shapley contribution 0.0025003864298987115\n",
            "Individual fairness, f_j = 0.7927781740365358\n",
            "Group fairness, f_g = 0.872000002861023\n",
            "Incentive fairness, f_r = 0.8516596277169302\n",
            "Orchestrator fairness, f_o = 0.5920000000000001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2024-03-20 12:30:36,420 | server.py:125 | fit progress: (20, 0.030459371605127062, {'accuracy': 0.7473172188680051}, 5871.093143730999)\n",
            "INFO:flwr:fit progress: (20, 0.030459371605127062, {'accuracy': 0.7473172188680051}, 5871.093143730999)\n",
            "INFO flwr 2024-03-20 12:30:36,429 | server.py:171 | evaluate_round 20: no clients selected, cancel\n",
            "INFO:flwr:evaluate_round 20: no clients selected, cancel\n",
            "INFO flwr 2024-03-20 12:30:36,432 | server.py:153 | FL finished in 5871.105456963\n",
            "INFO:flwr:FL finished in 5871.105456963\n",
            "INFO flwr 2024-03-20 12:30:36,441 | app.py:226 | app_fit: losses_distributed []\n",
            "INFO:flwr:app_fit: losses_distributed []\n",
            "INFO flwr 2024-03-20 12:30:36,443 | app.py:227 | app_fit: metrics_distributed_fit {'f_j': [(1, 0.7599797810426164), (2, 0.3328334485251469), (3, 0.11787373966839894), (4, 0.43974446718211796), (5, 0.5659404628765677), (6, 0.8516084974260238), (7, 0.12995805364329807), (8, 0.9342112648744338), (9, 0.7829044423911735), (10, 0.8717665710944317), (11, 0.9534105822789635), (12, 0.9573816327224879), (13, 0.961276683706735), (14, 0.9495832810410197), (15, 0.8644995495620715), (16, 0.8716110136822411), (17, 0.8239823707716293), (18, 0.9107058682302024), (19, 0.8494745850768001), (20, 0.7927781740365358)], 'f_g': [(1, 0.18400002121925352), (2, 0.2880000174045563), (3, 0.560000017285347), (4, 0.6400000125169754), (5, 0.8320000037550926), (6, 0.8560000039637089), (7, 0.8960000030696392), (8, 0.9600000001490117), (9, 0.8640000052750111), (10, 0.8080000065267086), (11, 0.9120000012218952), (12, 0.9120000027120113), (13, 0.7200000070035457), (14, 0.7040000051259995), (15, 0.5600000143051147), (16, 0.6880000121891499), (17, 0.8720000073313713), (18, 0.7120000034570694), (19, 0.5680000126361847), (20, 0.872000002861023)], 'f_r': [(1, nan), (2, 0.2465727158639456), (3, 0.11710640817127986), (4, 0.2049796946328666), (5, 0.47279759726143344), (6, 0.821839212128635), (7, 0.12880649658176407), (8, 0.9195422209277923), (9, 0.8605649463875312), (10, 0.8331769808727318), (11, 0.9658721732257778), (12, 0.9206740029956576), (13, 0.9677217988507221), (14, 0.9490532070326061), (15, 0.8700301511141978), (16, 0.8859122512855468), (17, 0.8296701637833819), (18, 0.9074961646730932), (19, 0.7799238107677074), (20, 0.8516596277169302)], 'f_o': [(1, 0.048), (2, 0.11200000000000002), (3, 0.248), (4, 0.336), (5, 0.42400000000000004), (6, 0.624), (7, 0.56), (8, 0.568), (9, 0.6080000000000001), (10, 0.624), (11, 0.592), (12, 0.4880000000000001), (13, 0.6880000000000001), (14, 0.688), (15, 0.744), (16, 0.6880000000000001), (17, 0.672), (18, 0.64), (19, 0.768), (20, 0.5920000000000001)]}\n",
            "INFO:flwr:app_fit: metrics_distributed_fit {'f_j': [(1, 0.7599797810426164), (2, 0.3328334485251469), (3, 0.11787373966839894), (4, 0.43974446718211796), (5, 0.5659404628765677), (6, 0.8516084974260238), (7, 0.12995805364329807), (8, 0.9342112648744338), (9, 0.7829044423911735), (10, 0.8717665710944317), (11, 0.9534105822789635), (12, 0.9573816327224879), (13, 0.961276683706735), (14, 0.9495832810410197), (15, 0.8644995495620715), (16, 0.8716110136822411), (17, 0.8239823707716293), (18, 0.9107058682302024), (19, 0.8494745850768001), (20, 0.7927781740365358)], 'f_g': [(1, 0.18400002121925352), (2, 0.2880000174045563), (3, 0.560000017285347), (4, 0.6400000125169754), (5, 0.8320000037550926), (6, 0.8560000039637089), (7, 0.8960000030696392), (8, 0.9600000001490117), (9, 0.8640000052750111), (10, 0.8080000065267086), (11, 0.9120000012218952), (12, 0.9120000027120113), (13, 0.7200000070035457), (14, 0.7040000051259995), (15, 0.5600000143051147), (16, 0.6880000121891499), (17, 0.8720000073313713), (18, 0.7120000034570694), (19, 0.5680000126361847), (20, 0.872000002861023)], 'f_r': [(1, nan), (2, 0.2465727158639456), (3, 0.11710640817127986), (4, 0.2049796946328666), (5, 0.47279759726143344), (6, 0.821839212128635), (7, 0.12880649658176407), (8, 0.9195422209277923), (9, 0.8605649463875312), (10, 0.8331769808727318), (11, 0.9658721732257778), (12, 0.9206740029956576), (13, 0.9677217988507221), (14, 0.9490532070326061), (15, 0.8700301511141978), (16, 0.8859122512855468), (17, 0.8296701637833819), (18, 0.9074961646730932), (19, 0.7799238107677074), (20, 0.8516596277169302)], 'f_o': [(1, 0.048), (2, 0.11200000000000002), (3, 0.248), (4, 0.336), (5, 0.42400000000000004), (6, 0.624), (7, 0.56), (8, 0.568), (9, 0.6080000000000001), (10, 0.624), (11, 0.592), (12, 0.4880000000000001), (13, 0.6880000000000001), (14, 0.688), (15, 0.744), (16, 0.6880000000000001), (17, 0.672), (18, 0.64), (19, 0.768), (20, 0.5920000000000001)]}\n",
            "INFO flwr 2024-03-20 12:30:36,445 | app.py:228 | app_fit: metrics_distributed {}\n",
            "INFO:flwr:app_fit: metrics_distributed {}\n",
            "INFO flwr 2024-03-20 12:30:36,447 | app.py:229 | app_fit: losses_centralized [(0, 0.12916205187897586), (1, 0.12440716528799435), (2, 0.11417746463517893), (3, 0.10189816944783231), (4, 0.0852109406238719), (5, 0.07075520375400926), (6, 0.05819377410638946), (7, 0.054700535158014076), (8, 0.04880917371635493), (9, 0.043506447428553016), (10, 0.04056903966977807), (11, 0.0388432933192499), (12, 0.03668699396609538), (13, 0.035100623289079425), (14, 0.03447514242467522), (15, 0.0331225147897977), (16, 0.032545702634577366), (17, 0.03124842846014388), (18, 0.0296954416426688), (19, 0.02995062164064687), (20, 0.030459371605127062)]\n",
            "INFO:flwr:app_fit: losses_centralized [(0, 0.12916205187897586), (1, 0.12440716528799435), (2, 0.11417746463517893), (3, 0.10189816944783231), (4, 0.0852109406238719), (5, 0.07075520375400926), (6, 0.05819377410638946), (7, 0.054700535158014076), (8, 0.04880917371635493), (9, 0.043506447428553016), (10, 0.04056903966977807), (11, 0.0388432933192499), (12, 0.03668699396609538), (13, 0.035100623289079425), (14, 0.03447514242467522), (15, 0.0331225147897977), (16, 0.032545702634577366), (17, 0.03124842846014388), (18, 0.0296954416426688), (19, 0.02995062164064687), (20, 0.030459371605127062)]\n",
            "INFO flwr 2024-03-20 12:30:36,449 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.005546903334542274), (1, 0.05179954344718708), (2, 0.12260789793697864), (3, 0.24822392422076675), (4, 0.35297506026923814), (5, 0.46704926076845943), (6, 0.5456446141702046), (7, 0.5746378512149851), (8, 0.6201437928018262), (9, 0.6475156273334329), (10, 0.6650523755680242), (11, 0.6783222750837369), (12, 0.6903761227145692), (13, 0.7060567917564483), (14, 0.711411686898641), (15, 0.7252789452349967), (16, 0.7368847737503467), (17, 0.7350926972884176), (18, 0.7428796962003712), (19, 0.7450557890469993), (20, 0.7473172188680051)]}\n",
            "INFO:flwr:app_fit: metrics_centralized {'accuracy': [(0, 0.005546903334542274), (1, 0.05179954344718708), (2, 0.12260789793697864), (3, 0.24822392422076675), (4, 0.35297506026923814), (5, 0.46704926076845943), (6, 0.5456446141702046), (7, 0.5746378512149851), (8, 0.6201437928018262), (9, 0.6475156273334329), (10, 0.6650523755680242), (11, 0.6783222750837369), (12, 0.6903761227145692), (13, 0.7060567917564483), (14, 0.711411686898641), (15, 0.7252789452349967), (16, 0.7368847737503467), (17, 0.7350926972884176), (18, 0.7428796962003712), (19, 0.7450557890469993), (20, 0.7473172188680051)]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Server-side evaluation loss 0.030459371605127062 / accuracy 0.7473172188680051\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "History (loss, centralized):\n",
              "\tround 0: 0.12916205187897586\n",
              "\tround 1: 0.12440716528799435\n",
              "\tround 2: 0.11417746463517893\n",
              "\tround 3: 0.10189816944783231\n",
              "\tround 4: 0.0852109406238719\n",
              "\tround 5: 0.07075520375400926\n",
              "\tround 6: 0.05819377410638946\n",
              "\tround 7: 0.054700535158014076\n",
              "\tround 8: 0.04880917371635493\n",
              "\tround 9: 0.043506447428553016\n",
              "\tround 10: 0.04056903966977807\n",
              "\tround 11: 0.0388432933192499\n",
              "\tround 12: 0.03668699396609538\n",
              "\tround 13: 0.035100623289079425\n",
              "\tround 14: 0.03447514242467522\n",
              "\tround 15: 0.0331225147897977\n",
              "\tround 16: 0.032545702634577366\n",
              "\tround 17: 0.03124842846014388\n",
              "\tround 18: 0.0296954416426688\n",
              "\tround 19: 0.02995062164064687\n",
              "\tround 20: 0.030459371605127062\n",
              "History (metrics, distributed, fit):\n",
              "{'f_j': [(1, 0.7599797810426164), (2, 0.3328334485251469), (3, 0.11787373966839894), (4, 0.43974446718211796), (5, 0.5659404628765677), (6, 0.8516084974260238), (7, 0.12995805364329807), (8, 0.9342112648744338), (9, 0.7829044423911735), (10, 0.8717665710944317), (11, 0.9534105822789635), (12, 0.9573816327224879), (13, 0.961276683706735), (14, 0.9495832810410197), (15, 0.8644995495620715), (16, 0.8716110136822411), (17, 0.8239823707716293), (18, 0.9107058682302024), (19, 0.8494745850768001), (20, 0.7927781740365358)], 'f_g': [(1, 0.18400002121925352), (2, 0.2880000174045563), (3, 0.560000017285347), (4, 0.6400000125169754), (5, 0.8320000037550926), (6, 0.8560000039637089), (7, 0.8960000030696392), (8, 0.9600000001490117), (9, 0.8640000052750111), (10, 0.8080000065267086), (11, 0.9120000012218952), (12, 0.9120000027120113), (13, 0.7200000070035457), (14, 0.7040000051259995), (15, 0.5600000143051147), (16, 0.6880000121891499), (17, 0.8720000073313713), (18, 0.7120000034570694), (19, 0.5680000126361847), (20, 0.872000002861023)], 'f_r': [(1, nan), (2, 0.2465727158639456), (3, 0.11710640817127986), (4, 0.2049796946328666), (5, 0.47279759726143344), (6, 0.821839212128635), (7, 0.12880649658176407), (8, 0.9195422209277923), (9, 0.8605649463875312), (10, 0.8331769808727318), (11, 0.9658721732257778), (12, 0.9206740029956576), (13, 0.9677217988507221), (14, 0.9490532070326061), (15, 0.8700301511141978), (16, 0.8859122512855468), (17, 0.8296701637833819), (18, 0.9074961646730932), (19, 0.7799238107677074), (20, 0.8516596277169302)], 'f_o': [(1, 0.048), (2, 0.11200000000000002), (3, 0.248), (4, 0.336), (5, 0.42400000000000004), (6, 0.624), (7, 0.56), (8, 0.568), (9, 0.6080000000000001), (10, 0.624), (11, 0.592), (12, 0.4880000000000001), (13, 0.6880000000000001), (14, 0.688), (15, 0.744), (16, 0.6880000000000001), (17, 0.672), (18, 0.64), (19, 0.768), (20, 0.5920000000000001)]}History (metrics, centralized):\n",
              "{'accuracy': [(0, 0.005546903334542274), (1, 0.05179954344718708), (2, 0.12260789793697864), (3, 0.24822392422076675), (4, 0.35297506026923814), (5, 0.46704926076845943), (6, 0.5456446141702046), (7, 0.5746378512149851), (8, 0.6201437928018262), (9, 0.6475156273334329), (10, 0.6650523755680242), (11, 0.6783222750837369), (12, 0.6903761227145692), (13, 0.7060567917564483), (14, 0.711411686898641), (15, 0.7252789452349967), (16, 0.7368847737503467), (17, 0.7350926972884176), (18, 0.7428796962003712), (19, 0.7450557890469993), (20, 0.7473172188680051)]}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Creating Shapley instance\n",
        "shap = Shapley(testloader, test, set_parameters, NUM_CLIENTS)\n",
        "# Create FedAvg strategy:\n",
        "strategy = fl.server.strategy.FedAvg(\n",
        "    fraction_fit=SELECTION_RATE, # sample all clients for training\n",
        "    fraction_evaluate=0.0, # Disabling federated evaluation\n",
        "    min_fit_clients=int(NUM_CLIENTS*SELECTION_RATE), # never sample less that this for training\n",
        "    min_evaluate_clients=int(NUM_CLIENTS*SELECTION_RATE), # never sample less than this for evaluation\n",
        "    min_available_clients=NUM_CLIENTS, # has to wait until all clients are available\n",
        "    # Passing initial_parameters prevents flower asking a client:\n",
        "    initial_parameters=fl.common.ndarrays_to_parameters(get_parameters(Net())),\n",
        "    # Called whenever fit or evaluate metrics are received from clients:\n",
        "    fit_metrics_aggregation_fn = fit_callback,\n",
        "    # Evaluate function is called by flower every round for central evaluation:\n",
        "    evaluate_fn=evaluate,\n",
        "    # Altering client behaviour with the config dictionary:\n",
        "    on_fit_config_fn=fit_config,\n",
        ")\n",
        "\n",
        "# Specifying client resources\n",
        "client_resources = None # {\"num_cpus\": 1, \"num_gpus\": 0.0}\n",
        "if DEVICE.type == \"cuda\":\n",
        "    # here we are asigning an entire GPU for each client.\n",
        "    client_resources = {\"num_cpus\": 1, \"num_gpus\": 1.0}\n",
        "\n",
        "# Start simulation\n",
        "fl.simulation.start_simulation(\n",
        "    client_fn=client_fn,\n",
        "    num_clients=NUM_CLIENTS,\n",
        "    config=fl.server.ServerConfig(num_rounds=NUM_ROUNDS),  # We can configure the number of rounds - we want this to have a threshold at which it cuts off\n",
        "    strategy=strategy,\n",
        "    client_resources=client_resources,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving data:\n",
        "with open('/content/drive/My Drive/FL/Results/'+ path_extension + '.json', \"w\") as outfile:\n",
        "  data = json.dump(data, outfile)\n",
        "print(f\"Elapsed time in {mode} mode = {timedelta(seconds=time.perf_counter()-start)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TNg6s9uD4NN",
        "outputId": "e3961377-c6da-4a03-a303-5aa1bc8a66c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time in cuda mode = 1:48:04.107980\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
